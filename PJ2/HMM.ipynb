{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43474480",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from check import check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1e5c94",
   "metadata": {},
   "source": [
    "1. 初始状态概率（π）\n",
    "\n",
    "$$\n",
    "\\pi_i = \\frac{\\text{Count}(q_1 = s_i)}{\\text{总序列数}}\n",
    "$$\n",
    "\n",
    "2. 状态转移概率（A）\n",
    "\n",
    "$$\n",
    "a_{ij} = \\frac{\\text{Count}(s_i \\rightarrow s_j)}{\\text{Count}(s_i \\rightarrow \\text{任意状态})}\n",
    "$$\n",
    "\n",
    "3. 观测发射概率（B）\n",
    "\n",
    "$$\n",
    "b_j(k) = \\frac{\\text{Count}(s_j \\text{生成} o_k)}{\\text{Count}(s_j)}\n",
    "$$\n",
    "\n",
    "符号说明：\n",
    "- $s_i$ ：隐藏状态\n",
    "- $v_k$ ：观测符号\n",
    "- $q_t$ ：t时刻的状态\n",
    "- $o_t$ ：t时刻的观测\n",
    "- $T$ ：序列长度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21cd797a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self, states, observations, pi, A, B):\n",
    "        self.states = states\n",
    "        self.observations = observations\n",
    "        self.pi = pi\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "\n",
    "    # 维特比算法\n",
    "    def viterbi(self, obs_seq):\n",
    "        T = len(obs_seq)\n",
    "        N = len(self.states)\n",
    "        delta = np.zeros((T, N))\n",
    "        psi = np.zeros((T, N), dtype=int)  # 回溯路径\n",
    "\n",
    "        # 初始化\n",
    "        for i, q in enumerate(self.states):\n",
    "            emit_prob = self.B[q].get(obs_seq[0], 1e-8)  # 未知观测给极小概率\n",
    "            delta[0][i] = self.pi[q] * emit_prob\n",
    "\n",
    "        # 递推\n",
    "        for t in range(1, T):\n",
    "            for j, q_j in enumerate(self.states):\n",
    "                max_val = -1\n",
    "                max_idx = -1\n",
    "                for i, q_i in enumerate(self.states):\n",
    "                    emit_prob = self.B[q_j].get(obs_seq[t], 1e-8)\n",
    "                    val = delta[t-1][i] * self.A[q_i][q_j] * emit_prob\n",
    "                    if val > max_val:\n",
    "                        max_val = val\n",
    "                        max_idx = i\n",
    "                delta[t][j] = max_val\n",
    "                psi[t][j] = max_idx\n",
    "\n",
    "        # 回溯\n",
    "        path = [np.argmax(delta[T-1])]\n",
    "        for t in range(T-1, 0, -1):\n",
    "            path.insert(0, psi[t][path[0]])\n",
    "\n",
    "        return [self.states[idx] for idx in path]\n",
    "    \n",
    "    # 监督学习\n",
    "    # obs_seqs: 观测序列列表\n",
    "    # state_seqs: 对应的状态序列列表\n",
    "    def supervised_learning(self, state_seqs, obs_seqs):\n",
    "        # 初始化计数\n",
    "        pi_counts = {q: 0 for q in self.states}\n",
    "        A_counts = {q_i: {q_j: 0 for q_j in self.states} for q_i in self.states}\n",
    "        B_counts = {q: {o: 0 for o in self.observations} for q in self.states}\n",
    "\n",
    "        # 统计初始状态\n",
    "        for seq in state_seqs:\n",
    "            first_state = seq[0]\n",
    "            pi_counts[first_state] += 1\n",
    "\n",
    "        # 统计转移和观测\n",
    "        for state_seq, obs_seq in zip(state_seqs, obs_seqs):\n",
    "            for t in range(len(state_seq)-1):\n",
    "                current_state = state_seq[t]\n",
    "                next_state = state_seq[t+1]\n",
    "                current_obs = obs_seq[t]\n",
    "\n",
    "                A_counts[current_state][next_state] += 1\n",
    "                B_counts[current_state][current_obs] += 1\n",
    "\n",
    "            # 处理最后一个观测\n",
    "            last_state = state_seq[-1]\n",
    "            last_obs = obs_seq[-1]\n",
    "            B_counts[last_state][last_obs] += 1\n",
    "\n",
    "        # 计算初始概率 pi\n",
    "        total_seqs = len(state_seqs)\n",
    "        for q in self.states:\n",
    "            self.pi[q] = pi_counts[q] / total_seqs\n",
    "\n",
    "        # 计算转移概率A\n",
    "        for q_i in self.states:\n",
    "            total_trans = sum(A_counts[q_i].values())\n",
    "            if total_trans > 0:\n",
    "                for q_j in self.states:\n",
    "                    self.A[q_i][q_j] = A_counts[q_i][q_j] / total_trans\n",
    "            else:\n",
    "                # 如果没有观察到转移，均匀分布\n",
    "                for q_j in self.states:\n",
    "                    self.A[q_i][q_j] = 1.0 / len(self.states)\n",
    "\n",
    "        # 计算发射概率B\n",
    "        for q in self.states:\n",
    "            total_obs = sum(B_counts[q].values())\n",
    "            if total_obs > 0:\n",
    "                for o in self.observations:\n",
    "                    self.B[q][o] = B_counts[q][o] / total_obs\n",
    "            else:\n",
    "                # 如果没有观察到发射，均匀分布\n",
    "                for o in self.observations:\n",
    "                    self.B[q][o] = 1.0 / len(self.observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfe9c5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path):\n",
    "    # 初始化数据结构\n",
    "    states = set()\n",
    "    observations = set()\n",
    "    state_seqs = []\n",
    "    obs_seqs = []\n",
    "    \n",
    "    current_state_seq = []\n",
    "    current_obs_seq = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # 空行表示句子结束\n",
    "                if current_state_seq and current_obs_seq:\n",
    "                    state_seqs.append(current_state_seq)\n",
    "                    obs_seqs.append(current_obs_seq)\n",
    "                    current_state_seq = []\n",
    "                    current_obs_seq = []\n",
    "                continue\n",
    "                \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:  # 确保有词和标签\n",
    "                word = parts[0]\n",
    "                tag = parts[-1]  # 假设标签在最后\n",
    "                \n",
    "                # 更新状态和观测集合\n",
    "                states.add(tag)\n",
    "                observations.add(word)\n",
    "                \n",
    "                # 添加到当前序列\n",
    "                current_state_seq.append(tag)\n",
    "                current_obs_seq.append(word)\n",
    "    \n",
    "    # 处理最后一个句子（如果文件不以空行结尾）\n",
    "    if current_state_seq and current_obs_seq:\n",
    "        state_seqs.append(current_state_seq)\n",
    "        obs_seqs.append(current_obs_seq)\n",
    "    \n",
    "    # 转换为列表并排序（为了确定性）\n",
    "    states = sorted(states)\n",
    "    observations = sorted(observations)\n",
    "    \n",
    "    return {\n",
    "        'states': states,\n",
    "        'observations': observations,\n",
    "        'state_seqs': state_seqs,\n",
    "        'obs_seqs': obs_seqs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d1133dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "# train_data_path = \"./NER/English/train.txt\"\n",
    "train_data_path = \"./NER/Chinese/train.txt\"\n",
    "train_data = process_data(train_data_path)\n",
    "\n",
    "states = train_data['states']\n",
    "observations = train_data['observations']\n",
    "state_seqs = train_data['state_seqs']\n",
    "obs_seqs = train_data['obs_seqs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39deebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化参数\n",
    "pi = {q: 0 for q in states}\n",
    "A = {q_i: {q_j: 0 for q_j in states} for q_i in states}\n",
    "B = {q: {o: 0 for o in observations} for q in states}\n",
    "\n",
    "# 创建HMM模型\n",
    "hmm = HMM(states, observations, pi, A, B)\n",
    "\n",
    "# 进行监督学习\n",
    "hmm.supervised_learning(state_seqs, obs_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19970692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.0000    0.0000    0.0000      1842\n",
      "       I-PER     0.0000    0.0000    0.0000      1307\n",
      "       B-ORG     0.0337    0.0306    0.0321      1341\n",
      "       I-ORG     0.0000    0.0000    0.0000       751\n",
      "       B-LOC     0.0000    0.0000    0.0000      1837\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       922\n",
      "      I-MISC     0.0000    0.0000    0.0000       346\n",
      "\n",
      "   micro avg     0.0337    0.0048    0.0084      8603\n",
      "   macro avg     0.0042    0.0038    0.0040      8603\n",
      "weighted avg     0.0053    0.0048    0.0050      8603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 验证集\n",
    "valid_data_path = \"NER/English/validation.txt\"\n",
    "valid_data = process_data(valid_data_path)\n",
    "\n",
    "output_path = \"output/hmm_validation_output.txt\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for obs_seq, pred_states in zip(valid_data['obs_seqs'], [hmm.viterbi(seq) for seq in valid_data['obs_seqs']]):\n",
    "        for word, tag in zip(obs_seq, pred_states):\n",
    "            fout.write(f\"{word} {tag}\\n\")\n",
    "        fout.write(\"\\n\")  # 句子间空行\n",
    "\n",
    "check(language = \"English\", gold_path=valid_data_path, my_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e120ba0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      B-NAME     0.9659    0.7589    0.8500       112\n",
      "      M-NAME     0.9242    0.7439    0.8243        82\n",
      "      E-NAME     0.9091    0.7143    0.8000       112\n",
      "      S-NAME     0.0000    0.0000    0.0000         0\n",
      "      B-CONT     0.0154    1.0000    0.0302        28\n",
      "      M-CONT     0.9796    0.9057    0.9412        53\n",
      "      E-CONT     0.9615    0.8929    0.9259        28\n",
      "      S-CONT     0.0000    0.0000    0.0000         0\n",
      "       B-EDU     0.8947    0.9107    0.9027       112\n",
      "       M-EDU     0.9298    0.8883    0.9086       179\n",
      "       E-EDU     0.9123    0.9286    0.9204       112\n",
      "       S-EDU     0.0000    0.0000    0.0000         0\n",
      "     B-TITLE     0.8866    0.7922    0.8368       770\n",
      "     M-TITLE     0.9099    0.7626    0.8298      1921\n",
      "     E-TITLE     0.9564    0.8545    0.9026       770\n",
      "     S-TITLE     0.0000    0.0000    0.0000         0\n",
      "       B-ORG     0.8780    0.7953    0.8346       552\n",
      "       M-ORG     0.9240    0.8205    0.8692      4312\n",
      "       E-ORG     0.8612    0.7754    0.8160       552\n",
      "       S-ORG     0.0000    0.0000    0.0000         0\n",
      "      B-RACE     1.0000    0.7857    0.8800        14\n",
      "      M-RACE     0.0000    0.0000    0.0000         0\n",
      "      E-RACE     1.0000    0.7857    0.8800        14\n",
      "      S-RACE     0.0000    0.0000    0.0000         0\n",
      "       B-PRO     0.5854    0.7273    0.6486        33\n",
      "       M-PRO     0.4719    0.6176    0.5350        68\n",
      "       E-PRO     0.6585    0.8182    0.7297        33\n",
      "       S-PRO     0.0000    0.0000    0.0000         0\n",
      "       B-LOC     0.3333    0.3333    0.3333         6\n",
      "       M-LOC     0.5833    0.3333    0.4242        21\n",
      "       E-LOC     0.5000    0.5000    0.5000         6\n",
      "       S-LOC     0.0000    0.0000    0.0000         0\n",
      "\n",
      "   micro avg     0.7525    0.8046    0.7777      9890\n",
      "   macro avg     0.5638    0.5452    0.5351      9890\n",
      "weighted avg     0.9063    0.8046    0.8502      9890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data_path = \"pj2_test/chinese_test.txt\"\n",
    "test_data = process_data(test_data_path)\n",
    "\n",
    "output_path = \"output/hmm_validation_output.txt\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for obs_seq, pred_states in zip(test_data['obs_seqs'], [hmm.viterbi(seq) for seq in test_data['obs_seqs']]):\n",
    "        for word, tag in zip(obs_seq, pred_states):\n",
    "            fout.write(f\"{word} {tag}\\n\")\n",
    "        fout.write(\"\\n\")  # 句子间空行\n",
    "\n",
    "check(language = \"Chinese\", gold_path=test_data_path, my_path=output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
