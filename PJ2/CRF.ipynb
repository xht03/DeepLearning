{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "062be403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from check import check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af22309a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 状态特征\n",
    "def unigram_template(off):\n",
    "    def feature(seq, pos, current_tag, prev_tag):\n",
    "        idx = pos + off\n",
    "        if 0 <= idx < len(seq):\n",
    "            return hash(seq[idx])\n",
    "        else:\n",
    "            return 0\n",
    "    return feature\n",
    "\n",
    "# U00, U01, U02, U03, U04\n",
    "feature_functions = [\n",
    "    unigram_template(-2),\n",
    "    unigram_template(-1),\n",
    "    unigram_template(0),\n",
    "    unigram_template(1),\n",
    "    unigram_template(2),\n",
    "]\n",
    "is_transition_feature = [False] * len(feature_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4110d77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 组合特征\n",
    "def unigram_pair_template(off1, off2):\n",
    "    def feature(seq, pos, current_tag, prev_tag):\n",
    "        idx1 = pos + off1\n",
    "        idx2 = pos + off2\n",
    "        if 0 <= idx1 < len(seq) and 0 <= idx2 < len(seq):\n",
    "            return hash((seq[idx1], seq[idx2]))\n",
    "        else:\n",
    "            return 0\n",
    "    return feature\n",
    "\n",
    "# U05, U06, U07, U08, U09\n",
    "feature_functions += [\n",
    "    unigram_pair_template(-2, -1),\n",
    "    unigram_pair_template(-1, 0),\n",
    "    unigram_pair_template(-1, 1),\n",
    "    unigram_pair_template(0, 1),\n",
    "    unigram_pair_template(1, 2),\n",
    "]\n",
    "is_transition_feature += [False] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9aca5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转移特征\n",
    "def bigram_template(off):\n",
    "    def feature(seq, pos, current_tag, prev_tag):\n",
    "        idx = pos + off\n",
    "        if 0 <= idx < len(seq) and prev_tag is not None:\n",
    "            return hash((seq[idx], prev_tag, current_tag))\n",
    "        else:\n",
    "            return 0\n",
    "    return feature\n",
    "\n",
    "# B00, B01, ..., B04\n",
    "feature_functions += [\n",
    "    bigram_template(-2),\n",
    "    bigram_template(-1),\n",
    "    bigram_template(0),\n",
    "    bigram_template(1),\n",
    "    bigram_template(2),\n",
    "]\n",
    "is_transition_feature += [True] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9c2b617",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp(arr):\n",
    "    max_val = np.max(arr)\n",
    "    return max_val + np.log(np.sum(np.exp(arr - max_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62e58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRF:\n",
    "    # n_tags: 标签数量\n",
    "    # feature_functions: 特征函数列表\n",
    "    def __init__(self, n_tags, feature_functions, is_transition_feature):\n",
    "        self.n_tags = n_tags\n",
    "        self.feature_functions = feature_functions\n",
    "        self.is_transition_feature = is_transition_feature\n",
    "        self.weights = np.zeros(len(feature_functions)) # 权重向量，每个特征函数对应一个权重\n",
    "\n",
    "    # 保存模型参数\n",
    "    def save_params(self, filepath):\n",
    "        np.save(filepath, self.weights)\n",
    "        print(f\"CRF weights saved to {filepath}\")\n",
    "\n",
    "    # 加载模型参数\n",
    "    def load_params(self, filepath):\n",
    "        self.weights = np.load(filepath)\n",
    "        print(f\"CRF weights loaded from {filepath}\")\n",
    "    \n",
    "    # 前向算法\n",
    "    # alpha[t, tag]: 给定观测序列的前t+1个词时，以tag作为第t个词的标签的所有路径的“分数”之和\n",
    "    def forward(self, seq):\n",
    "        T = len(seq)\n",
    "        alpha = np.full((T, self.n_tags), -np.inf)\n",
    "\n",
    "        # 初始化\n",
    "        for tag in range(self.n_tags):\n",
    "            alpha[0, tag] = self.state_score(seq, 0, tag, None)\n",
    "        \n",
    "        # 递推\n",
    "        for t in range(1, T):\n",
    "            for tag in range(self.n_tags):\n",
    "                scores = []\n",
    "                for prev_tag in range(self.n_tags):\n",
    "                    score = alpha[t-1, prev_tag] + self.transition_score(seq, t, tag, prev_tag)\n",
    "                    scores.append(score)\n",
    "                alpha[t, tag] = logsumexp(scores) + self.state_score(seq, t, tag, None)\n",
    "        return alpha\n",
    "\n",
    "    # 后向算法\n",
    "    # beta[t, tag]: 在给定观测序列的第t个词处，已知该词的标签为tag，从t到序列末尾的所有可能标签路径的“分数”之和。\n",
    "    def backward(self, seq):\n",
    "        T = len(seq)\n",
    "        beta = np.full((T, self.n_tags), -np.inf)\n",
    "        \n",
    "        # 初始化\n",
    "        beta[T-1, :] = 0  # log(1) = 0\n",
    "\n",
    "        # 递推\n",
    "        for t in range(T-2, -1, -1):\n",
    "            for tag in range(self.n_tags):\n",
    "                scores = []\n",
    "                for next_tag in range(self.n_tags):\n",
    "                    score = (\n",
    "                        beta[t+1, next_tag]\n",
    "                        + self.transition_score(seq, t+1, next_tag, tag)\n",
    "                        + self.state_score(seq, t+1, next_tag, tag)\n",
    "                    )\n",
    "                    scores.append(score)\n",
    "                beta[t, tag] = logsumexp(scores)\n",
    "        return beta\n",
    "\n",
    "    # 计算边缘概率\n",
    "    # marginals[t, tag]: 在给定观测序列x的条件下，第t个词的标签为tag的概率\n",
    "    def compute_marginals(self, seq):\n",
    "        alpha = self.forward(seq)\n",
    "        beta = self.backward(seq)\n",
    "        logZ = logsumexp(alpha[-1, :])\n",
    "        \n",
    "        marginals = np.zeros((len(seq), self.n_tags))\n",
    "        for t in range(len(seq)):\n",
    "            for tag in range(self.n_tags):\n",
    "                marginals[t, tag] = np.exp(alpha[t, tag] + beta[t, tag] - logZ)\n",
    "        return marginals\n",
    "    \n",
    "    # 维特比解码\n",
    "    def viterbi_decode(self, seq):\n",
    "        T = len(seq)\n",
    "        viterbi = np.full((T, self.n_tags), -np.inf)\n",
    "        backptrs = np.zeros((T, self.n_tags), dtype=int)    # 回溯指针\n",
    "\n",
    "        # 初始化\n",
    "        for tag in range(self.n_tags):\n",
    "            viterbi[0, tag] = self.state_score(seq, 0, tag, None)\n",
    "\n",
    "        # 递推\n",
    "        for t in range(1, T):\n",
    "            for tag in range(self.n_tags):\n",
    "                max_score = -np.inf\n",
    "                best_prev_tag = 0\n",
    "                for prev_tag in range(self.n_tags):\n",
    "                    score = viterbi[t-1, prev_tag] + self.transition_score(seq, t, tag, prev_tag)\n",
    "                    if score > max_score:\n",
    "                        max_score = score\n",
    "                        best_prev_tag = prev_tag\n",
    "                viterbi[t, tag] = max_score + self.state_score(seq, t, tag, best_prev_tag)\n",
    "                backptrs[t, tag] = best_prev_tag\n",
    "\n",
    "        # 回溯\n",
    "        best_path = []\n",
    "        best_last_tag = np.argmax(viterbi[-1, :])\n",
    "        best_path.append(best_last_tag)\n",
    "\n",
    "        for t in range(T-1, 0, -1):\n",
    "            best_last_tag = backptrs[t, best_last_tag]\n",
    "            best_path.insert(0, best_last_tag)\n",
    "\n",
    "        return best_path\n",
    "    \n",
    "\n",
    "    # 计算状态特征得分 (直接返回log分数)\n",
    "    def state_score(self, sequence, position, current_tag, prev_tag):\n",
    "        score = 0\n",
    "        for i, func in enumerate(self.feature_functions):\n",
    "            if not self.is_transition_feature[i]:\n",
    "                score += self.weights[i] * func(sequence, position, current_tag, prev_tag)\n",
    "        return score\n",
    "\n",
    "    # 计算转移特征得分 (直接返回log分数)\n",
    "    def transition_score(self, sequence, position, current_tag, prev_tag):\n",
    "        score = 0\n",
    "        for i, func in enumerate(self.feature_functions):\n",
    "            if self.is_transition_feature[i]:\n",
    "                score += self.weights[i] * func(sequence, position, current_tag, prev_tag)\n",
    "        return score\n",
    "\n",
    "\n",
    "    # 训练CRF模型\n",
    "    def train(self, seqs, tag_seqs, lr=0.01, max_iter=100):\n",
    "        for iteration in range(max_iter):\n",
    "            total_loss = 0\n",
    "            grad = np.zeros(len(self.weights))\n",
    "\n",
    "            for seq, tag_seq in zip(seqs, tag_seqs):\n",
    "                # 计算模型预测的边缘概率\n",
    "                marginals = self.compute_marginals(seq)\n",
    "\n",
    "                empirical_expectation = np.zeros(len(self.weights))\n",
    "                model_expectation = np.zeros(len(self.weights))\n",
    "\n",
    "                # 计算经验特征期望\n",
    "                # empirical_expectation[i]: 第i个特征函数在真实标签下的总和\n",
    "                for t in range(len(seq)):\n",
    "                    current_tag = tag_seq[t]\n",
    "                    prev_tag = tag_seq[t-1] if t > 0 else None\n",
    "                    for i, func in enumerate(self.feature_functions):\n",
    "                        empirical_expectation[i] += func(seq, t, current_tag, prev_tag)\n",
    "\n",
    "                # 计算模型特征期望\n",
    "                # model_expectation[i]: 第i个特征函数在模型预测分布下的期望值\n",
    "                for t in range(len(seq)):\n",
    "                    for current_tag in range(self.n_tags):\n",
    "                        for prev_tag in range(self.n_tags):\n",
    "                            if t == 0:\n",
    "                                prev_tag = None\n",
    "                            for i, func in enumerate(self.feature_functions):\n",
    "                                model_expectation[i] += marginals[t, current_tag] * \\\n",
    "                                                       func(seq, t, current_tag, prev_tag)\n",
    "\n",
    "                # 更新梯度\n",
    "                grad += empirical_expectation - model_expectation\n",
    "\n",
    "                # 计算对数似然损失\n",
    "                alpha = self.forward(seq)\n",
    "                logZ = logsumexp(alpha[-1, :])\n",
    "                sequence_score = 0\n",
    "                for t in range(len(seq)):\n",
    "                    current_tag = tag_seq[t]\n",
    "                    prev_tag = tag_seq[t-1] if t > 0 else None\n",
    "                    for i, func in enumerate(self.feature_functions):\n",
    "                        sequence_score += self.weights[i] * func(seq, t, current_tag, prev_tag)\n",
    "                total_loss += sequence_score - logZ\n",
    "\n",
    "            # 更新权重\n",
    "            self.weights += lr * grad\n",
    "\n",
    "            print(f\"Iteration {iteration + 1}, Loss: {total_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "802cb738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(file_path):\n",
    "    # 初始化数据结构\n",
    "    tags = set()\n",
    "    words = set()\n",
    "    tag_seqs = []\n",
    "    word_seqs = []\n",
    "    \n",
    "    current_state_seq = []\n",
    "    current_obs_seq = []\n",
    "    \n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:  # 空行表示句子结束\n",
    "                if current_state_seq and current_obs_seq:\n",
    "                    tag_seqs.append(current_state_seq)\n",
    "                    word_seqs.append(current_obs_seq)\n",
    "                    current_state_seq = []\n",
    "                    current_obs_seq = []\n",
    "                continue\n",
    "                \n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:  # 确保有词和标签\n",
    "                word = parts[0]\n",
    "                tag = parts[-1]  # 假设标签在最后\n",
    "                \n",
    "                # 更新状态和观测集合\n",
    "                tags.add(tag)\n",
    "                words.add(word)\n",
    "                \n",
    "                # 添加到当前序列\n",
    "                current_state_seq.append(tag)\n",
    "                current_obs_seq.append(word)\n",
    "    \n",
    "    # 处理最后一个句子（如果文件不以空行结尾）\n",
    "    if current_state_seq and current_obs_seq:\n",
    "        tag_seqs.append(current_state_seq)\n",
    "        word_seqs.append(current_obs_seq)\n",
    "    \n",
    "    # 转换为列表并排序（为了确定性）\n",
    "    tags = sorted(tags)\n",
    "    words = sorted(words)\n",
    "    \n",
    "    return {\n",
    "        'tags': tags,\n",
    "        'words': words,\n",
    "        'tag_seqs': tag_seqs,\n",
    "        'word_seqs': word_seqs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebefba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据\n",
    "train_data_path = \"./NER/English/train.txt\"\n",
    "train_data = process_data(train_data_path)\n",
    "\n",
    "tags = train_data['tags']\n",
    "words = train_data['words']\n",
    "tag_seqs = train_data['tag_seqs']\n",
    "word_seqs = train_data['word_seqs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42a66632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, Loss: -447401.06566181174\n",
      "Iteration 2, Loss: -6.47036864634497e+45\n",
      "Iteration 3, Loss: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m crf = CRF(\u001b[38;5;28mlen\u001b[39m(tags), feature_functions, is_transition_feature)\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# 训练CRF模型\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mcrf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword_seqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag_seqs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 154\u001b[39m, in \u001b[36mCRF.train\u001b[39m\u001b[34m(self, seqs, tag_seqs, lr, max_iter)\u001b[39m\n\u001b[32m    151\u001b[39m grad += empirical_expectation - model_expectation\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# 计算对数似然损失\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m alpha = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m logZ = logsumexp(alpha[-\u001b[32m1\u001b[39m, :])\n\u001b[32m    156\u001b[39m sequence_score = \u001b[32m0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mCRF.forward\u001b[39m\u001b[34m(self, seq)\u001b[39m\n\u001b[32m     25\u001b[39m             score = alpha[t-\u001b[32m1\u001b[39m, prev_tag] + \u001b[38;5;28mself\u001b[39m.transition_score(seq, t, tag, prev_tag)\n\u001b[32m     26\u001b[39m             scores.append(score)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m         alpha[t, tag] = \u001b[43mlogsumexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscores\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.state_score(seq, t, tag, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m alpha\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36mlogsumexp\u001b[39m\u001b[34m(arr)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mlogsumexp\u001b[39m(arr):\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     max_val = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m max_val + np.log(np.sum(np.exp(arr - max_val)))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3199\u001b[39m, in \u001b[36mmax\u001b[39m\u001b[34m(a, axis, out, keepdims, initial, where)\u001b[39m\n\u001b[32m   3080\u001b[39m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_max_dispatcher)\n\u001b[32m   3081\u001b[39m \u001b[38;5;129m@set_module\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mnumpy\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m   3082\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mmax\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=np._NoValue, initial=np._NoValue,\n\u001b[32m   3083\u001b[39m          where=np._NoValue):\n\u001b[32m   3084\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3085\u001b[39m \u001b[33;03m    Return the maximum of an array or maximum along an axis.\u001b[39;00m\n\u001b[32m   3086\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3197\u001b[39m \u001b[33;03m    5\u001b[39;00m\n\u001b[32m   3198\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3199\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapreduction\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaximum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3200\u001b[39m \u001b[43m                          \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:86\u001b[39m, in \u001b[36m_wrapreduction\u001b[39m\u001b[34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     84\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m reduction(axis=axis, out=out, **passkwargs)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mufunc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpasskwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "crf = CRF(len(tags), feature_functions, is_transition_feature)\n",
    "\n",
    "# 训练CRF模型\n",
    "crf.train(word_seqs, tag_seqs, lr=0.01, max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68c692f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_path = \"./NER/English/validation.txt\"\n",
    "valid_data = process_data(valid_data_path)\n",
    "\n",
    "output_path = \"./crf_validation_output.txt\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for seq, tag_seq in zip(valid_data['word_seqs'], valid_data['tag_seqs']):\n",
    "        predicted_tags = crf.viterbi_decode(seq)\n",
    "        for word, tag in zip(seq, predicted_tags):\n",
    "            fout.write(f\"{word} {tags[tag]}\\n\")\n",
    "        fout.write(\"\\n\")  # 句子间空行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9361f677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-PER     0.0000    0.0000    0.0000      1842\n",
      "       I-PER     0.0000    0.0000    0.0000      1307\n",
      "       B-ORG     0.0000    0.0000    0.0000      1341\n",
      "       I-ORG     0.0000    0.0000    0.0000       751\n",
      "       B-LOC     0.0358    1.0000    0.0691      1837\n",
      "       I-LOC     0.0000    0.0000    0.0000       257\n",
      "      B-MISC     0.0000    0.0000    0.0000       922\n",
      "      I-MISC     0.0000    0.0000    0.0000       346\n",
      "\n",
      "   micro avg     0.0358    0.2135    0.0613      8603\n",
      "   macro avg     0.0045    0.1250    0.0086      8603\n",
      "weighted avg     0.0076    0.2135    0.0147      8603\n",
      "\n"
     ]
    }
   ],
   "source": [
    "check(language = \"English\", gold_path=\"NER/English/validation.txt\", my_path=\"crf_validation_output.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
