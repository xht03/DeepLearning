{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b771f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "sys.path.append(os.path.abspath('../../Python-Table/task2'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "import pandas as pd\n",
    "from lib.Net import *\n",
    "from lib.Func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddb3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size, 1, 28, 28) -> (batch_size, 2, 24, 24) -> (batch_size, 2*24*24) -> (batch_size, 64) -> (batch_size, 10)\n",
    "architecture = [\n",
    "    {\"module\": Conv2d, \"params\": {\"in_channels\": 1, \"out_channels\": 2, \"kernel_size\": 5, \"activation\": \"gelu\"}},\n",
    "    {\"module\": Flatten},\n",
    "    {\"module\": Mlp, \"params\": {\"input_dim\": 1152, \"output_dim\": 64, \"activation\": \"gelu\"}},\n",
    "    {\"module\": Dropout, \"params\": {\"p\": 0.3}},\n",
    "    {\"module\": Mlp, \"params\": {\"input_dim\": 64, \"output_dim\": 10, \"activation\": \"softmax\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c462c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578484b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data/MNIST/train-images.idx3-ubyte\"\n",
    "labelpath = \"../data/MNIST/train-labels.idx1-ubyte\"\n",
    "modelpath = \"../model/task2/MNIST.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a186dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = idx2numpy.convert_from_file(datapath)    # (60000, 28, 28)\n",
    "data = np.expand_dims(data, axis=1)             # 添加通道维度 -> (60000, 1, 28, 28)\n",
    "\n",
    "label = idx2numpy.convert_from_file(labelpath)\n",
    "one_hot_labels = one_hot(label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b5ae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 78/117, Loss: 4.1923\n",
      "Batch 79/117, Loss: 4.1295\n",
      "Batch 80/117, Loss: 4.2193\n",
      "Batch 81/117, Loss: 4.1385\n",
      "Batch 82/117, Loss: 4.1385\n",
      "Batch 83/117, Loss: 4.2552\n",
      "Batch 84/117, Loss: 4.1116\n",
      "Batch 85/117, Loss: 4.2372\n",
      "Batch 86/117, Loss: 4.2103\n",
      "Batch 87/117, Loss: 4.2462\n",
      "Batch 88/117, Loss: 4.0846\n",
      "Batch 89/117, Loss: 4.0308\n",
      "Batch 90/117, Loss: 4.1744\n",
      "Batch 91/117, Loss: 4.2103\n",
      "Batch 92/117, Loss: 4.1564\n",
      "Batch 93/117, Loss: 4.1834\n",
      "Batch 94/117, Loss: 4.1923\n",
      "Batch 95/117, Loss: 4.2911\n",
      "Batch 96/117, Loss: 4.2013\n",
      "Batch 97/117, Loss: 4.1744\n",
      "Batch 98/117, Loss: 4.1116\n",
      "Batch 99/117, Loss: 4.0757\n",
      "Batch 100/117, Loss: 4.2193\n",
      "Batch 101/117, Loss: 4.2552\n",
      "Batch 102/117, Loss: 4.1654\n",
      "Batch 103/117, Loss: 4.2282\n",
      "Batch 104/117, Loss: 4.2103\n",
      "Batch 105/117, Loss: 4.1295\n",
      "Batch 106/117, Loss: 4.1475\n",
      "Batch 107/117, Loss: 4.1295\n",
      "Batch 108/117, Loss: 4.2103\n",
      "Batch 109/117, Loss: 4.0936\n",
      "Batch 110/117, Loss: 4.0757\n",
      "Batch 111/117, Loss: 4.1834\n",
      "Batch 112/117, Loss: 4.0846\n",
      "Batch 113/117, Loss: 4.2462\n",
      "Batch 114/117, Loss: 4.2013\n",
      "Batch 115/117, Loss: 4.1295\n",
      "Batch 116/117, Loss: 4.1475\n",
      "Batch 117/117, Loss: 4.2462\n",
      "Batch 118/117, Loss: 4.2222\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "pbar =tqdm(range(epochs))\n",
    "\n",
    "for i in pbar:\n",
    "    # data, one_hot_labels = shuffle(data, one_hot_labels)\n",
    "    net.train(data, one_hot_labels, batch_size=512, lr=0.1, lossfunc=\"cross_entropy\")\n",
    "\n",
    "    y_hat = net.predict(data)\n",
    "    loss = cross_entropy_loss(one_hot_labels, y_hat)\n",
    "    y_hat = np.argmax(y_hat, axis=1)    # (60000, 10) -> (60000,)\n",
    "    accuracy = np.mean(y_hat == one_hot_labels.argmax(axis=1))\n",
    "    pbar.set_postfix({\"loss\": loss, \"accuracy\": f\"{accuracy*100:.2f}%\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.save_params(modelpath_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda0e9bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
