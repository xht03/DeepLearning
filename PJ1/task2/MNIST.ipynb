{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d9b53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a33a56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5dfd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc5b6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, num_classes):\n",
    "    # one-hot 编码\n",
    "    one_hot_labels = np.zeros((labels.shape[0], num_classes))\n",
    "    for i in range(labels.shape[0]):\n",
    "        one_hot_labels[i, labels[i]] = 1\n",
    "    return one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0691d41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_22501/468675981.py:7: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
      "  data = torch.from_numpy(data).float()\n"
     ]
    }
   ],
   "source": [
    "datapath = \"../data/MNIST/train-images.idx3-ubyte\"\n",
    "labelpath = \"../data/MNIST/train-labels.idx1-ubyte\"\n",
    "modelpath = \"../model/task2/MNIST.pth\"\n",
    "\n",
    "data = idx2numpy.convert_from_file(datapath)    # (60000, 28, 28)\n",
    "data = np.expand_dims(data, axis=1)             # 添加通道维度 -> (60000, 1, 28, 28)\n",
    "data = torch.from_numpy(data).float()\n",
    "\n",
    "label = idx2numpy.convert_from_file(labelpath)\n",
    "one_hot_labels = one_hot(label, 10)\n",
    "one_hot_labels = torch.from_numpy(one_hot_labels).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2eb343",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datapath = \"../valid/MNIST/t10k-images.idx3-ubyte\"\n",
    "valid_labelpath = \"../valid/MNIST/t10k-labels.idx1-ubyte\"\n",
    "\n",
    "valid_data = idx2numpy.convert_from_file(valid_datapath)\n",
    "valid_data = np.expand_dims(valid_data, axis=1)\n",
    "valid_data = torch.from_numpy(valid_data).float()\n",
    "\n",
    "valid_label = idx2numpy.convert_from_file(valid_labelpath)\n",
    "valid_one_hot_labels = one_hot(valid_label, 10)\n",
    "valid_one_hot_labels = torch.from_numpy(valid_one_hot_labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa37655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(data, one_hot_labels)\n",
    "valid_dataset = TensorDataset(valid_data, valid_one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72d7bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100            # 训练轮数\n",
    "\n",
    "batch_size = 128        # 批大小\n",
    "inital_lr = 0.001       # 初始学习率\n",
    "lr_patience = 10        # 学习率衰减的耐心\n",
    "lr_decay = 0.5          # 学习率衰减系数\n",
    "\n",
    "best_accuracy = 0.0     # 最佳准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97a21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size, True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size, False)\n",
    "\n",
    "model = MNIST().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=inital_lr, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_decay, patience=lr_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = tqdm(range(epochs), desc=\"Training\")\n",
    "for i in pbar:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for x, y in train_loader:\n",
    "        # 加载进GPU\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        output = model(x)\n",
    "        # 计算损失\n",
    "        loss = loss_func(output, y)\n",
    "        running_loss += loss.item()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "    # 计算验证集损失和准确率\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # 预测\n",
    "            pred = model(x)\n",
    "            # 计算损失\n",
    "            loss = loss_func(pred, y)\n",
    "            test_loss += loss.item()\n",
    "            # 计算准确率\n",
    "            accuracy += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(y, dim=1)).item()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "    test_loss /= len(valid_loader)\n",
    "    accuracy /= len(valid_loader.dataset)\n",
    "    scheduler.step(test_loss)  # 更新学习率\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), modelpath)\n",
    "\n",
    "    pbar.set_postfix(\n",
    "        loss=running_loss,\n",
    "        test_loss=test_loss,\n",
    "        accuracy=f\"{accuracy*100:.2f}%\",\n",
    "        best_accuracy=f\"{best_accuracy*100:.2f}%\",\n",
    "        lr=optimizer.param_groups[0]['lr'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3574cc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"architecture:\", model)\n",
    "print(\"param\", sum(p.numel() for p in model.parameters()))\n",
    "print(\"savepath:\", modelpath)\n",
    "print(\"best_accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08e51847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For interview\n",
    "interview_data_path = \"../valid/MNIST/t10k-images.idx3-ubyte\"\n",
    "interview_label_path = \"../valid/MNIST/t10k-labels.idx1-ubyte\"\n",
    "\n",
    "interview_data = idx2numpy.convert_from_file(interview_data_path)\n",
    "interview_data = np.expand_dims(interview_data, axis=1)\n",
    "interview_data = torch.from_numpy(interview_data).float().to(device)\n",
    "\n",
    "interview_label = idx2numpy.convert_from_file(interview_label_path)\n",
    "interview_labels = one_hot(interview_label, 10)\n",
    "interview_labels = torch.from_numpy(interview_labels).float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8d9bda69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interview Accuracy: 99.31%\n"
     ]
    }
   ],
   "source": [
    "# For interview\n",
    "model.load_state_dict(torch.load(modelpath))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    pred = model(interview_data)\n",
    "    pred_labels = torch.argmax(pred, dim=1)\n",
    "    true_labels = torch.argmax(interview_labels, dim=1)\n",
    "    accuracy = torch.sum(pred_labels == true_labels).item() / len(interview_data)\n",
    "    print(\"Interview Accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
