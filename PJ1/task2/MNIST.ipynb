{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b771f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "import pandas as pd\n",
    "from lib.Net import *\n",
    "from lib.Func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ddb3987",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (batch_size, 1, 28, 28) -> (batch_size, 2, 24, 24) -> (batch_size, 2*24*24) -> (batch_size, 64) -> (batch_size, 10)\n",
    "architecture = [\n",
    "    {\"module\": Conv2d, \"params\": {\"in_channels\": 1, \"out_channels\": 2, \"kernel_size\": 5}},\n",
    "    {\"module\": Flatten},\n",
    "    {\"module\": Mlp, \"params\": {\"input_dim\": 1152, \"output_dim\": 64, \"activation\": \"gelu\"}},\n",
    "    {\"module\": Dropout, \"params\": {\"p\": 0.2}},\n",
    "    {\"module\": Mlp, \"params\": {\"input_dim\": 64, \"output_dim\": 10, \"activation\": \"softmax\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c462c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "578484b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data/MNIST/train-images.idx3-ubyte\"\n",
    "labelpath = \"../data/MNIST/train-labels.idx1-ubyte\"\n",
    "modelpath = \"../model/task2/MNIST.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a186dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = idx2numpy.convert_from_file(datapath)    # (60000, 28, 28)\n",
    "data = np.expand_dims(data, axis=1)             # 添加通道维度 -> (60000, 1, 28, 28)\n",
    "\n",
    "label = idx2numpy.convert_from_file(labelpath)\n",
    "one_hot_labels = one_hot(label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b5ae00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/937, Loss: 2.3033\n",
      "Batch 2/937, Loss: 2.5388\n",
      "Batch 3/937, Loss: 4.3180\n",
      "Batch 4/937, Loss: 4.1744\n",
      "Batch 5/937, Loss: 4.1744\n",
      "Batch 6/937, Loss: 4.3180\n",
      "Batch 7/937, Loss: 4.2462\n",
      "Batch 8/937, Loss: 3.9590\n",
      "Batch 9/937, Loss: 4.2462\n",
      "Batch 10/937, Loss: 3.9590\n",
      "Batch 11/937, Loss: 4.3180\n",
      "Batch 12/937, Loss: 4.3180\n",
      "Batch 13/937, Loss: 4.1744\n",
      "Batch 14/937, Loss: 4.2462\n",
      "Batch 15/937, Loss: 4.1744\n",
      "Batch 16/937, Loss: 4.0308\n",
      "Batch 17/937, Loss: 4.1744\n",
      "Batch 18/937, Loss: 4.2462\n",
      "Batch 19/937, Loss: 3.9590\n",
      "Batch 20/937, Loss: 4.2462\n",
      "Batch 21/937, Loss: 3.7436\n",
      "Batch 22/937, Loss: 4.3180\n",
      "Batch 23/937, Loss: 4.2462\n",
      "Batch 24/937, Loss: 4.1744\n",
      "Batch 25/937, Loss: 4.1744\n",
      "Batch 26/937, Loss: 3.8872\n",
      "Batch 27/937, Loss: 4.1026\n",
      "Batch 28/937, Loss: 4.2462\n",
      "Batch 29/937, Loss: 3.8872\n",
      "Batch 30/937, Loss: 4.1744\n",
      "Batch 31/937, Loss: 4.3180\n",
      "Batch 32/937, Loss: 4.2462\n",
      "Batch 33/937, Loss: 4.0308\n",
      "Batch 34/937, Loss: 4.3180\n",
      "Batch 35/937, Loss: 4.3180\n",
      "Batch 36/937, Loss: 4.1744\n",
      "Batch 37/937, Loss: 4.1744\n",
      "Batch 38/937, Loss: 4.1026\n",
      "Batch 39/937, Loss: 3.9590\n",
      "Batch 40/937, Loss: 4.2462\n",
      "Batch 41/937, Loss: 3.9590\n",
      "Batch 42/937, Loss: 4.2462\n",
      "Batch 43/937, Loss: 4.1744\n",
      "Batch 44/937, Loss: 4.2462\n",
      "Batch 45/937, Loss: 3.9590\n",
      "Batch 46/937, Loss: 4.1744\n",
      "Batch 47/937, Loss: 4.3898\n",
      "Batch 48/937, Loss: 4.4616\n",
      "Batch 49/937, Loss: 4.2462\n",
      "Batch 50/937, Loss: 4.1744\n",
      "Batch 51/937, Loss: 4.3898\n",
      "Batch 52/937, Loss: 3.8872\n",
      "Batch 53/937, Loss: 4.3180\n",
      "Batch 54/937, Loss: 4.3180\n",
      "Batch 55/937, Loss: 4.2462\n",
      "Batch 56/937, Loss: 3.6718\n",
      "Batch 57/937, Loss: 4.1026\n",
      "Batch 58/937, Loss: 4.2462\n",
      "Batch 59/937, Loss: 4.1026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:21<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 60/937, Loss: 4.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[32m      5\u001b[39m     data, one_hot_labels = shuffle(data, one_hot_labels)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcross_entropy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     y_hat = net.predict(data)\n\u001b[32m      9\u001b[39m     loss = cross_entropy_loss(one_hot_labels, y_hat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/PJ1/lib/Net.py:100\u001b[39m, in \u001b[36mNet.train\u001b[39m\u001b[34m(self, X, Y, batch_size, lr, lossfunc)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[32m     99\u001b[39m dL = \u001b[38;5;28mself\u001b[39m.loss_derivative(Y_batch, y_hat)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.loss(Y_batch,\u001b[38;5;250m \u001b[39my_hat)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/PJ1/lib/Net.py:74\u001b[39m, in \u001b[36mNet.backward\u001b[39m\u001b[34m(self, outputs, dL, lr)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, outputs, dL, lr):\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.net) - \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         dL = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/PJ1/lib/Net.py:294\u001b[39m, in \u001b[36mConv2d.backward\u001b[39m\u001b[34m(self, X, dL, lr)\u001b[39m\n\u001b[32m    292\u001b[39m                 w_start = w * \u001b[38;5;28mself\u001b[39m.stride\n\u001b[32m    293\u001b[39m                 \u001b[38;5;66;03m# (in_channels, kernel_size, kernel_size) = (in_channels, kernel_size, kernel_size) * scalar\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m                 dW[j] += X_padded[i, :, h_start : h_start + \u001b[38;5;28mself\u001b[39m.kernel_size, w_start : w_start + \u001b[38;5;28mself\u001b[39m.kernel_size] * dL[i, j, h, w]\n\u001b[32m    296\u001b[39m \u001b[38;5;66;03m# ---------------------------------------\u001b[39;00m\n\u001b[32m    297\u001b[39m db = np.sum(dL, axis=(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)) / batch_size\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "pbar =tqdm(range(epochs))\n",
    "\n",
    "for i in pbar:\n",
    "    data, one_hot_labels = shuffle(data, one_hot_labels)\n",
    "    net.train(data, one_hot_labels, batch_size=64, lr=10, lossfunc=\"cross_entropy\")\n",
    "\n",
    "    y_hat = net.predict(data)\n",
    "    loss = cross_entropy_loss(one_hot_labels, y_hat)\n",
    "    y_hat = np.argmax(y_hat, axis=1)    # (60000, 10) -> (60000,)\n",
    "    accuracy = np.mean(y_hat == one_hot_labels.argmax(axis=1))\n",
    "    pbar.set_postfix({\"loss\": loss, \"accuracy\": f\"{accuracy*100:.2f}%\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.save_params(modelpath_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "199311a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
