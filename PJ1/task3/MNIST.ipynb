{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d9b53ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a33a56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5120a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 残差块\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        # 如果输入输出维度不匹配，使用1x1卷积调整\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(residual)\n",
    "        out = self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5dfd879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            ResidualBlock(32, 32),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            ResidualBlock(32, 64),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 7 * 7, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 10),\n",
    "        )\n",
    "\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc5b6dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot(labels, num_classes):\n",
    "    # one-hot 编码\n",
    "    one_hot_labels = np.zeros((labels.shape[0], num_classes))\n",
    "    for i in range(labels.shape[0]):\n",
    "        one_hot_labels[i, labels[i]] = 1\n",
    "    return one_hot_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0691d41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data/MNIST/train-images.idx3-ubyte\"\n",
    "labelpath = \"../data/MNIST/train-labels.idx1-ubyte\"\n",
    "modelpath = \"../model/task3/MNIST.pth\"\n",
    "\n",
    "data = idx2numpy.convert_from_file(datapath)    # (60000, 28, 28)\n",
    "data = np.expand_dims(data, axis=1)             # 添加通道维度 -> (60000, 1, 28, 28)\n",
    "data = torch.from_numpy(data).float()\n",
    "\n",
    "label = idx2numpy.convert_from_file(labelpath)\n",
    "one_hot_labels = one_hot(label, 10)\n",
    "one_hot_labels = torch.from_numpy(one_hot_labels).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e2eb343",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datapath = \"../test/MNIST/t10k-images.idx3-ubyte\"\n",
    "test_labelpath = \"../test/MNIST/t10k-labels.idx1-ubyte\"\n",
    "\n",
    "test_data = idx2numpy.convert_from_file(test_datapath)\n",
    "test_data = np.expand_dims(test_data, axis=1)\n",
    "test_data = torch.from_numpy(test_data).float()\n",
    "\n",
    "test_label = idx2numpy.convert_from_file(test_labelpath)\n",
    "test_one_hot_labels = one_hot(test_label, 10)\n",
    "test_one_hot_labels = torch.from_numpy(test_one_hot_labels).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fa37655",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(data, one_hot_labels)\n",
    "test_dataset = TensorDataset(test_data, test_one_hot_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72d7bfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100            # 训练轮数\n",
    "\n",
    "batch_size = 128        # 批大小\n",
    "inital_lr = 0.001       # 初始学习率\n",
    "lr_patience = 10        # 学习率衰减的耐心\n",
    "lr_decay = 0.5          # 学习率衰减系数\n",
    "\n",
    "best_accuracy = 0.0     # 最佳准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c97a21b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size, True)\n",
    "test_loader = DataLoader(test_dataset, batch_size, False)\n",
    "\n",
    "model = MNIST().to(device)\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=inital_lr, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=lr_decay, patience=lr_patience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "db68e2b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 40/100 [01:24<02:07,  2.12s/it, accuracy=99.57%, best_accuracy=99.63%, loss=0.00297, lr=0.00025, test_loss=0.0275]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m test_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m      6\u001b[39m accuracy = \u001b[32m0.0\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# 加载进GPU\u001b[39;49;00m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    706\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    707\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m708\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    711\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    712\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    713\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    714\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    762\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    763\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m764\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    765\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    766\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataset.py:211\u001b[39m, in \u001b[36mTensorDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/torch/utils/data/dataset.py:211\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(tensor[index] \u001b[38;5;28;01mfor\u001b[39;00m tensor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.tensors)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "pbar = tqdm(range(epochs), desc=\"Training\")\n",
    "for i in pbar:\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    test_loss = 0.0\n",
    "    accuracy = 0.0\n",
    "    for x, y in train_loader:\n",
    "        # 加载进GPU\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 清空梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        output = model(x)\n",
    "        # 计算损失\n",
    "        loss = loss_func(output, y)\n",
    "        running_loss += loss.item()\n",
    "        # 反向传播\n",
    "        loss.backward()\n",
    "        # 更新参数\n",
    "        optimizer.step()\n",
    "\n",
    "    # 计算验证集损失和准确率\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # 预测\n",
    "            pred = model(x)\n",
    "            # 计算损失\n",
    "            loss = loss_func(pred, y)\n",
    "            test_loss += loss.item()\n",
    "            # 计算准确率\n",
    "            accuracy += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(y, dim=1)).item()\n",
    "\n",
    "    running_loss /= len(train_loader)\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy /= len(test_loader.dataset)\n",
    "    scheduler.step(test_loss)  # 更新学习率\n",
    "\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        torch.save(model.state_dict(), modelpath)\n",
    "\n",
    "    pbar.set_postfix(\n",
    "        loss=running_loss,\n",
    "        test_loss=test_loss,\n",
    "        accuracy=f\"{accuracy*100:.2f}%\",\n",
    "        best_accuracy=f\"{best_accuracy*100:.2f}%\",\n",
    "        lr=optimizer.param_groups[0]['lr'],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3574cc4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "architecture: MNIST(\n",
      "  (net): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ResidualBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): Flatten(start_dim=1, end_dim=-1)\n",
      "    (8): Linear(in_features=3136, out_features=128, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Dropout(p=0.5, inplace=False)\n",
      "    (11): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "param 479498\n",
      "savepath: ../model/task3/MNIST.pth\n",
      "best_accuracy: 0.9963\n"
     ]
    }
   ],
   "source": [
    "print(\"architecture:\", model)\n",
    "print(\"param\", sum(p.numel() for p in model.parameters()))\n",
    "print(\"savepath:\", modelpath)\n",
    "print(\"best_accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d9bda69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: 0.02353939176172731\n",
      "test_accuracy: 99.63%\n"
     ]
    }
   ],
   "source": [
    "# For interview\n",
    "model.load_state_dict(torch.load(modelpath))\n",
    "\n",
    "test_loss = 0.0\n",
    "accuracy = 0.0\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # 预测\n",
    "        pred = model(x)\n",
    "        # 计算损失\n",
    "        loss = loss_func(pred, y)\n",
    "        test_loss += loss.item()\n",
    "        # 计算准确率\n",
    "        accuracy += torch.sum(torch.argmax(pred, dim=1) == torch.argmax(y, dim=1)).item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    accuracy /= len(test_loader.dataset)\n",
    "\n",
    "print(\"test_loss:\", test_loss)\n",
    "print(\"test_accuracy:\", f\"{accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
