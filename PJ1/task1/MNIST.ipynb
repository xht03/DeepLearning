{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ecd952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import idx2numpy\n",
    "import pandas as pd\n",
    "from lib.Net import *\n",
    "from lib.Func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7388beca",
   "metadata": {},
   "outputs": [],
   "source": [
    "architecture_2 = [\n",
    "    {\"module\": Flatten},\n",
    "    {\"module\": Mlp, \"params\": {\"input_dim\": 784, \"output_dim\": 256, \"activation\": \"relu\"}},\n",
    "    {\"module\": Mlp, \"params\": {\"input_dim\": 256, \"output_dim\": 64, \"activation\": \"relu\"}},\n",
    "    {\"module\": Mlp, \"params\": {\"input_dim\": 64, \"output_dim\": 10, \"activation\": \"softmax\"}},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d3163d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(architecture_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91a96198",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = \"../data/MNIST/train-images.idx3-ubyte\"\n",
    "labelpath = \"../data/MNIST/train-labels.idx1-ubyte\"\n",
    "modelpath_2 = \"../model/task1/MNIST.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "958ac022",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = idx2numpy.convert_from_file(datapath)    # (60000, 28, 28)\n",
    "data = np.expand_dims(data, axis=1)             # 添加通道维度 -> (60000, 1, 28, 28)\n",
    "\n",
    "label = idx2numpy.convert_from_file(labelpath)\n",
    "one_hot_labels = one_hot(label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0f3c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/937, Loss: 2.3255\n",
      "Batch 2/937, Loss: 2.2961\n",
      "Batch 3/937, Loss: 2.2959\n",
      "Batch 4/937, Loss: 2.2906\n",
      "Batch 5/937, Loss: 2.2912\n",
      "Batch 6/937, Loss: 2.2702\n",
      "Batch 7/937, Loss: 2.2574\n",
      "Batch 8/937, Loss: 2.2081\n",
      "Batch 9/937, Loss: 2.2360\n",
      "Batch 10/937, Loss: 2.2175\n",
      "Batch 11/937, Loss: 2.1932\n",
      "Batch 12/937, Loss: 2.1638\n",
      "Batch 13/937, Loss: 2.2118\n",
      "Batch 14/937, Loss: 2.1738\n",
      "Batch 15/937, Loss: 2.1590\n",
      "Batch 16/937, Loss: 2.2016\n",
      "Batch 17/937, Loss: 2.1284\n",
      "Batch 18/937, Loss: 2.1851\n",
      "Batch 19/937, Loss: 2.1243\n",
      "Batch 20/937, Loss: 2.1060\n",
      "Batch 21/937, Loss: 2.1323\n",
      "Batch 22/937, Loss: 2.0995\n",
      "Batch 23/937, Loss: 2.1106\n",
      "Batch 24/937, Loss: 2.0226\n",
      "Batch 25/937, Loss: 2.0548\n",
      "Batch 26/937, Loss: 2.0217\n",
      "Batch 27/937, Loss: 1.9414\n",
      "Batch 28/937, Loss: 2.0035\n",
      "Batch 29/937, Loss: 1.9915\n",
      "Batch 30/937, Loss: 1.9485\n",
      "Batch 31/937, Loss: 2.0046\n",
      "Batch 32/937, Loss: 1.9189\n",
      "Batch 33/937, Loss: 1.8878\n",
      "Batch 34/937, Loss: 1.8859\n",
      "Batch 35/937, Loss: 1.8636\n",
      "Batch 36/937, Loss: 1.8296\n",
      "Batch 37/937, Loss: 1.8016\n",
      "Batch 38/937, Loss: 1.7996\n",
      "Batch 39/937, Loss: 1.8560\n",
      "Batch 40/937, Loss: 1.7715\n",
      "Batch 41/937, Loss: 1.7045\n",
      "Batch 42/937, Loss: 1.7260\n",
      "Batch 43/937, Loss: 1.7253\n",
      "Batch 44/937, Loss: 1.6868\n",
      "Batch 45/937, Loss: 1.6579\n",
      "Batch 46/937, Loss: 1.6252\n",
      "Batch 47/937, Loss: 1.6481\n",
      "Batch 48/937, Loss: 1.5531\n",
      "Batch 49/937, Loss: 1.5224\n",
      "Batch 50/937, Loss: 1.6698\n",
      "Batch 51/937, Loss: 1.5394\n",
      "Batch 52/937, Loss: 1.4728\n",
      "Batch 53/937, Loss: 1.5039\n",
      "Batch 54/937, Loss: 1.4946\n",
      "Batch 55/937, Loss: 1.4786\n",
      "Batch 56/937, Loss: 1.4636\n",
      "Batch 57/937, Loss: 1.3640\n",
      "Batch 58/937, Loss: 1.3220\n",
      "Batch 59/937, Loss: 1.3710\n",
      "Batch 60/937, Loss: 1.2460\n",
      "Batch 61/937, Loss: 1.2320\n",
      "Batch 62/937, Loss: 1.3515\n",
      "Batch 63/937, Loss: 1.1513\n",
      "Batch 64/937, Loss: 1.2913\n",
      "Batch 65/937, Loss: 1.2548\n",
      "Batch 66/937, Loss: 1.1905\n",
      "Batch 67/937, Loss: 1.1709\n",
      "Batch 68/937, Loss: 1.0741\n",
      "Batch 69/937, Loss: 1.1682\n",
      "Batch 70/937, Loss: 1.2654\n",
      "Batch 71/937, Loss: 1.0600\n",
      "Batch 72/937, Loss: 1.0143\n",
      "Batch 73/937, Loss: 1.0267\n",
      "Batch 74/937, Loss: 1.1688\n",
      "Batch 75/937, Loss: 0.9121\n",
      "Batch 76/937, Loss: 1.0430\n",
      "Batch 77/937, Loss: 0.9436\n",
      "Batch 78/937, Loss: 0.9643\n",
      "Batch 79/937, Loss: 0.9363\n",
      "Batch 80/937, Loss: 0.9416\n",
      "Batch 81/937, Loss: 1.0765\n",
      "Batch 82/937, Loss: 0.9726\n",
      "Batch 83/937, Loss: 0.9320\n",
      "Batch 84/937, Loss: 0.8801\n",
      "Batch 85/937, Loss: 0.8985\n",
      "Batch 86/937, Loss: 0.7442\n",
      "Batch 87/937, Loss: 0.8779\n",
      "Batch 88/937, Loss: 0.8055\n",
      "Batch 89/937, Loss: 0.7801\n",
      "Batch 90/937, Loss: 0.8878\n",
      "Batch 91/937, Loss: 0.7509\n",
      "Batch 92/937, Loss: 0.8808\n",
      "Batch 93/937, Loss: 0.8693\n",
      "Batch 94/937, Loss: 0.9073\n",
      "Batch 95/937, Loss: 0.8272\n",
      "Batch 96/937, Loss: 0.7045\n",
      "Batch 97/937, Loss: 0.6816\n",
      "Batch 98/937, Loss: 0.7495\n",
      "Batch 99/937, Loss: 0.6883\n",
      "Batch 100/937, Loss: 0.6785\n",
      "Batch 101/937, Loss: 0.7800\n",
      "Batch 102/937, Loss: 0.6179\n",
      "Batch 103/937, Loss: 0.6445\n",
      "Batch 104/937, Loss: 0.8979\n",
      "Batch 105/937, Loss: 1.0346\n",
      "Batch 106/937, Loss: 0.6333\n",
      "Batch 107/937, Loss: 0.9256\n",
      "Batch 108/937, Loss: 0.7954\n",
      "Batch 109/937, Loss: 0.6850\n",
      "Batch 110/937, Loss: 0.7507\n",
      "Batch 111/937, Loss: 0.6780\n",
      "Batch 112/937, Loss: 0.6685\n",
      "Batch 113/937, Loss: 0.7609\n",
      "Batch 114/937, Loss: 0.7776\n",
      "Batch 115/937, Loss: 0.6161\n",
      "Batch 116/937, Loss: 0.6767\n",
      "Batch 117/937, Loss: 0.5821\n",
      "Batch 118/937, Loss: 0.7774\n",
      "Batch 119/937, Loss: 0.5947\n",
      "Batch 120/937, Loss: 0.6120\n",
      "Batch 121/937, Loss: 0.5935\n",
      "Batch 122/937, Loss: 0.6161\n",
      "Batch 123/937, Loss: 0.4935\n",
      "Batch 124/937, Loss: 0.6333\n",
      "Batch 125/937, Loss: 0.6276\n",
      "Batch 126/937, Loss: 0.6679\n",
      "Batch 127/937, Loss: 0.6667\n",
      "Batch 128/937, Loss: 0.6032\n",
      "Batch 129/937, Loss: 0.6952\n",
      "Batch 130/937, Loss: 0.6140\n",
      "Batch 131/937, Loss: 0.5364\n",
      "Batch 132/937, Loss: 0.6418\n",
      "Batch 133/937, Loss: 0.6445\n",
      "Batch 134/937, Loss: 0.5522\n",
      "Batch 135/937, Loss: 0.6225\n",
      "Batch 136/937, Loss: 0.7070\n",
      "Batch 137/937, Loss: 0.5936\n",
      "Batch 138/937, Loss: 0.5641\n",
      "Batch 139/937, Loss: 0.6420\n",
      "Batch 140/937, Loss: 0.4863\n",
      "Batch 141/937, Loss: 0.8038\n",
      "Batch 142/937, Loss: 0.5071\n",
      "Batch 143/937, Loss: 0.5898\n",
      "Batch 144/937, Loss: 0.5517\n",
      "Batch 145/937, Loss: 0.4913\n",
      "Batch 146/937, Loss: 0.4768\n",
      "Batch 147/937, Loss: 0.5175\n",
      "Batch 148/937, Loss: 0.5528\n",
      "Batch 149/937, Loss: 0.6602\n",
      "Batch 150/937, Loss: 0.6942\n",
      "Batch 151/937, Loss: 0.5806\n",
      "Batch 152/937, Loss: 0.5307\n",
      "Batch 153/937, Loss: 0.5053\n",
      "Batch 154/937, Loss: 0.6694\n",
      "Batch 155/937, Loss: 0.5568\n",
      "Batch 156/937, Loss: 0.6629\n",
      "Batch 157/937, Loss: 0.4188\n",
      "Batch 158/937, Loss: 0.4961\n",
      "Batch 159/937, Loss: 0.5704\n",
      "Batch 160/937, Loss: 0.5264\n",
      "Batch 161/937, Loss: 0.6622\n",
      "Batch 162/937, Loss: 0.4563\n",
      "Batch 163/937, Loss: 0.4815\n",
      "Batch 164/937, Loss: 0.4718\n",
      "Batch 165/937, Loss: 0.5757\n",
      "Batch 166/937, Loss: 0.4683\n",
      "Batch 167/937, Loss: 0.4979\n",
      "Batch 168/937, Loss: 0.5148\n",
      "Batch 169/937, Loss: 0.5385\n",
      "Batch 170/937, Loss: 0.5101\n",
      "Batch 171/937, Loss: 0.4230\n",
      "Batch 172/937, Loss: 0.4758\n",
      "Batch 173/937, Loss: 0.6893\n",
      "Batch 174/937, Loss: 0.5519\n",
      "Batch 175/937, Loss: 0.5577\n",
      "Batch 176/937, Loss: 0.5589\n",
      "Batch 177/937, Loss: 0.5123\n",
      "Batch 178/937, Loss: 0.4782\n",
      "Batch 179/937, Loss: 0.5355\n",
      "Batch 180/937, Loss: 0.4289\n",
      "Batch 181/937, Loss: 0.4838\n",
      "Batch 182/937, Loss: 0.3725\n",
      "Batch 183/937, Loss: 0.6237\n",
      "Batch 184/937, Loss: 0.5163\n",
      "Batch 185/937, Loss: 0.4371\n",
      "Batch 186/937, Loss: 0.2981\n",
      "Batch 187/937, Loss: 0.5682\n",
      "Batch 188/937, Loss: 0.5477\n",
      "Batch 189/937, Loss: 0.6047\n",
      "Batch 190/937, Loss: 0.6589\n",
      "Batch 191/937, Loss: 0.4708\n",
      "Batch 192/937, Loss: 0.4986\n",
      "Batch 193/937, Loss: 0.4232\n",
      "Batch 194/937, Loss: 0.6851\n",
      "Batch 195/937, Loss: 0.6513\n",
      "Batch 196/937, Loss: 0.4533\n",
      "Batch 197/937, Loss: 0.5372\n",
      "Batch 198/937, Loss: 0.4636\n",
      "Batch 199/937, Loss: 0.4791\n",
      "Batch 200/937, Loss: 0.8416\n",
      "Batch 201/937, Loss: 0.3858\n",
      "Batch 202/937, Loss: 0.5925\n",
      "Batch 203/937, Loss: 0.5809\n",
      "Batch 204/937, Loss: 0.2723\n",
      "Batch 205/937, Loss: 0.4752\n",
      "Batch 206/937, Loss: 0.5079\n",
      "Batch 207/937, Loss: 0.6612\n",
      "Batch 208/937, Loss: 0.4246\n",
      "Batch 209/937, Loss: 0.4668\n",
      "Batch 210/937, Loss: 0.3735\n",
      "Batch 211/937, Loss: 0.6117\n",
      "Batch 212/937, Loss: 0.2759\n",
      "Batch 213/937, Loss: 0.4267\n",
      "Batch 214/937, Loss: 0.6573\n",
      "Batch 215/937, Loss: 0.4518\n",
      "Batch 216/937, Loss: 0.6041\n",
      "Batch 217/937, Loss: 0.5382\n",
      "Batch 218/937, Loss: 0.4718\n",
      "Batch 219/937, Loss: 0.5205\n",
      "Batch 220/937, Loss: 0.3521\n",
      "Batch 221/937, Loss: 0.4285\n",
      "Batch 222/937, Loss: 0.4087\n",
      "Batch 223/937, Loss: 0.5120\n",
      "Batch 224/937, Loss: 0.4396\n",
      "Batch 225/937, Loss: 0.2878\n",
      "Batch 226/937, Loss: 0.4124\n",
      "Batch 227/937, Loss: 0.4522\n",
      "Batch 228/937, Loss: 0.4726\n",
      "Batch 229/937, Loss: 0.5821\n",
      "Batch 230/937, Loss: 0.4482\n",
      "Batch 231/937, Loss: 0.4905\n",
      "Batch 232/937, Loss: 0.5048\n",
      "Batch 233/937, Loss: 0.5218\n",
      "Batch 234/937, Loss: 0.3979\n",
      "Batch 235/937, Loss: 0.4943\n",
      "Batch 236/937, Loss: 0.4811\n",
      "Batch 237/937, Loss: 0.5605\n",
      "Batch 238/937, Loss: 0.4388\n",
      "Batch 239/937, Loss: 0.4636\n",
      "Batch 240/937, Loss: 0.4557\n",
      "Batch 241/937, Loss: 0.2853\n",
      "Batch 242/937, Loss: 0.5094\n",
      "Batch 243/937, Loss: 0.3457\n",
      "Batch 244/937, Loss: 0.3923\n",
      "Batch 245/937, Loss: 0.3609\n",
      "Batch 246/937, Loss: 0.4530\n",
      "Batch 247/937, Loss: 0.3742\n",
      "Batch 248/937, Loss: 0.3416\n",
      "Batch 249/937, Loss: 0.5077\n",
      "Batch 250/937, Loss: 0.2609\n",
      "Batch 251/937, Loss: 0.3141\n",
      "Batch 252/937, Loss: 0.4252\n",
      "Batch 253/937, Loss: 0.4046\n",
      "Batch 254/937, Loss: 0.6023\n",
      "Batch 255/937, Loss: 0.3832\n",
      "Batch 256/937, Loss: 0.3625\n",
      "Batch 257/937, Loss: 0.3578\n",
      "Batch 258/937, Loss: 0.2918\n",
      "Batch 259/937, Loss: 0.2999\n",
      "Batch 260/937, Loss: 0.3933\n",
      "Batch 261/937, Loss: 0.2944\n",
      "Batch 262/937, Loss: 0.4232\n",
      "Batch 263/937, Loss: 0.5954\n",
      "Batch 264/937, Loss: 0.4759\n",
      "Batch 265/937, Loss: 0.6460\n",
      "Batch 266/937, Loss: 0.3479\n",
      "Batch 267/937, Loss: 0.5971\n",
      "Batch 268/937, Loss: 0.4267\n",
      "Batch 269/937, Loss: 0.2958\n",
      "Batch 270/937, Loss: 0.3356\n",
      "Batch 271/937, Loss: 0.3760\n",
      "Batch 272/937, Loss: 0.3893\n",
      "Batch 273/937, Loss: 0.3355\n",
      "Batch 274/937, Loss: 0.3339\n",
      "Batch 275/937, Loss: 0.3630\n",
      "Batch 276/937, Loss: 0.3135\n",
      "Batch 277/937, Loss: 0.3877\n",
      "Batch 278/937, Loss: 0.3241\n",
      "Batch 279/937, Loss: 0.3724\n",
      "Batch 280/937, Loss: 0.5392\n",
      "Batch 281/937, Loss: 0.3762\n",
      "Batch 282/937, Loss: 0.5070\n",
      "Batch 283/937, Loss: 0.4330\n",
      "Batch 284/937, Loss: 0.7503\n",
      "Batch 285/937, Loss: 0.2995\n",
      "Batch 286/937, Loss: 0.3185\n",
      "Batch 287/937, Loss: 0.3061\n",
      "Batch 288/937, Loss: 0.4343\n",
      "Batch 289/937, Loss: 0.5300\n",
      "Batch 290/937, Loss: 0.5182\n",
      "Batch 291/937, Loss: 0.3329\n",
      "Batch 292/937, Loss: 0.4189\n",
      "Batch 293/937, Loss: 0.4226\n",
      "Batch 294/937, Loss: 0.5890\n",
      "Batch 295/937, Loss: 0.3638\n",
      "Batch 296/937, Loss: 0.2876\n",
      "Batch 297/937, Loss: 0.5163\n",
      "Batch 298/937, Loss: 0.6102\n",
      "Batch 299/937, Loss: 0.3972\n",
      "Batch 300/937, Loss: 0.3323\n",
      "Batch 301/937, Loss: 0.3063\n",
      "Batch 302/937, Loss: 0.3797\n",
      "Batch 303/937, Loss: 0.5420\n",
      "Batch 304/937, Loss: 0.4174\n",
      "Batch 305/937, Loss: 0.3352\n",
      "Batch 306/937, Loss: 0.4006\n",
      "Batch 307/937, Loss: 0.3789\n",
      "Batch 308/937, Loss: 0.3663\n",
      "Batch 309/937, Loss: 0.4747\n",
      "Batch 310/937, Loss: 0.4886\n",
      "Batch 311/937, Loss: 0.2704\n",
      "Batch 312/937, Loss: 0.6795\n",
      "Batch 313/937, Loss: 0.3628\n",
      "Batch 314/937, Loss: 0.4474\n",
      "Batch 315/937, Loss: 0.2702\n",
      "Batch 316/937, Loss: 0.5124\n",
      "Batch 317/937, Loss: 0.4868\n",
      "Batch 318/937, Loss: 0.3143\n",
      "Batch 319/937, Loss: 0.2747\n",
      "Batch 320/937, Loss: 0.2299\n",
      "Batch 321/937, Loss: 0.3632\n",
      "Batch 322/937, Loss: 0.5404\n",
      "Batch 323/937, Loss: 0.5572\n",
      "Batch 324/937, Loss: 0.4158\n",
      "Batch 325/937, Loss: 0.6588\n",
      "Batch 326/937, Loss: 0.3441\n",
      "Batch 327/937, Loss: 0.3347\n",
      "Batch 328/937, Loss: 0.4374\n",
      "Batch 329/937, Loss: 0.3810\n",
      "Batch 330/937, Loss: 0.4181\n",
      "Batch 331/937, Loss: 0.3939\n",
      "Batch 332/937, Loss: 0.2714\n",
      "Batch 333/937, Loss: 0.5400\n",
      "Batch 334/937, Loss: 0.3354\n",
      "Batch 335/937, Loss: 0.5166\n",
      "Batch 336/937, Loss: 0.5359\n",
      "Batch 337/937, Loss: 0.3418\n",
      "Batch 338/937, Loss: 0.4822\n",
      "Batch 339/937, Loss: 0.3140\n",
      "Batch 340/937, Loss: 0.5933\n",
      "Batch 341/937, Loss: 0.3842\n",
      "Batch 342/937, Loss: 0.2702\n",
      "Batch 343/937, Loss: 0.4366\n",
      "Batch 344/937, Loss: 0.2661\n",
      "Batch 345/937, Loss: 0.3622\n",
      "Batch 346/937, Loss: 0.4900\n",
      "Batch 347/937, Loss: 0.3017\n",
      "Batch 348/937, Loss: 0.3512\n",
      "Batch 349/937, Loss: 0.3728\n",
      "Batch 350/937, Loss: 0.3991\n",
      "Batch 351/937, Loss: 0.5176\n",
      "Batch 352/937, Loss: 0.3806\n",
      "Batch 353/937, Loss: 0.2600\n",
      "Batch 354/937, Loss: 0.2868\n",
      "Batch 355/937, Loss: 0.4501\n",
      "Batch 356/937, Loss: 0.4397\n",
      "Batch 357/937, Loss: 0.3969\n",
      "Batch 358/937, Loss: 0.3348\n",
      "Batch 359/937, Loss: 0.2788\n",
      "Batch 360/937, Loss: 0.4430\n",
      "Batch 361/937, Loss: 0.6034\n",
      "Batch 362/937, Loss: 0.3416\n",
      "Batch 363/937, Loss: 0.4135\n",
      "Batch 364/937, Loss: 0.3113\n",
      "Batch 365/937, Loss: 0.1644\n",
      "Batch 366/937, Loss: 0.3558\n",
      "Batch 367/937, Loss: 0.2616\n",
      "Batch 368/937, Loss: 0.3393\n",
      "Batch 369/937, Loss: 0.3272\n",
      "Batch 370/937, Loss: 0.4180\n",
      "Batch 371/937, Loss: 0.3512\n",
      "Batch 372/937, Loss: 0.4056\n",
      "Batch 373/937, Loss: 0.2471\n",
      "Batch 374/937, Loss: 0.3563\n",
      "Batch 375/937, Loss: 0.2835\n",
      "Batch 376/937, Loss: 0.2802\n",
      "Batch 377/937, Loss: 0.4432\n",
      "Batch 378/937, Loss: 0.2542\n",
      "Batch 379/937, Loss: 0.2693\n",
      "Batch 380/937, Loss: 0.3536\n",
      "Batch 381/937, Loss: 0.3541\n",
      "Batch 382/937, Loss: 0.2834\n",
      "Batch 383/937, Loss: 0.3505\n",
      "Batch 384/937, Loss: 0.3733\n",
      "Batch 385/937, Loss: 0.4284\n",
      "Batch 386/937, Loss: 0.4897\n",
      "Batch 387/937, Loss: 0.4586\n",
      "Batch 388/937, Loss: 0.3825\n",
      "Batch 389/937, Loss: 0.4550\n",
      "Batch 390/937, Loss: 0.3632\n",
      "Batch 391/937, Loss: 0.2897\n",
      "Batch 392/937, Loss: 0.2561\n",
      "Batch 393/937, Loss: 0.2836\n",
      "Batch 394/937, Loss: 0.3010\n",
      "Batch 395/937, Loss: 0.4844\n",
      "Batch 396/937, Loss: 0.5185\n",
      "Batch 397/937, Loss: 0.1725\n",
      "Batch 398/937, Loss: 0.5313\n",
      "Batch 399/937, Loss: 0.1789\n",
      "Batch 400/937, Loss: 0.3362\n",
      "Batch 401/937, Loss: 0.4510\n",
      "Batch 402/937, Loss: 0.5464\n",
      "Batch 403/937, Loss: 0.2864\n",
      "Batch 404/937, Loss: 0.1754\n",
      "Batch 405/937, Loss: 0.3245\n",
      "Batch 406/937, Loss: 0.2776\n",
      "Batch 407/937, Loss: 0.3147\n",
      "Batch 408/937, Loss: 0.3579\n",
      "Batch 409/937, Loss: 0.2992\n",
      "Batch 410/937, Loss: 0.3183\n",
      "Batch 411/937, Loss: 0.2692\n",
      "Batch 412/937, Loss: 0.3971\n",
      "Batch 413/937, Loss: 0.3059\n",
      "Batch 414/937, Loss: 0.2306\n",
      "Batch 415/937, Loss: 0.4747\n",
      "Batch 416/937, Loss: 0.3925\n",
      "Batch 417/937, Loss: 0.1916\n",
      "Batch 418/937, Loss: 0.1730\n",
      "Batch 419/937, Loss: 0.2469\n",
      "Batch 420/937, Loss: 0.3778\n",
      "Batch 421/937, Loss: 0.2817\n",
      "Batch 422/937, Loss: 0.3810\n",
      "Batch 423/937, Loss: 0.5464\n",
      "Batch 424/937, Loss: 0.4226\n",
      "Batch 425/937, Loss: 0.1892\n",
      "Batch 426/937, Loss: 0.3760\n",
      "Batch 427/937, Loss: 0.1706\n",
      "Batch 428/937, Loss: 0.3253\n",
      "Batch 429/937, Loss: 0.1314\n",
      "Batch 430/937, Loss: 0.3071\n",
      "Batch 431/937, Loss: 0.2531\n",
      "Batch 432/937, Loss: 0.5535\n",
      "Batch 433/937, Loss: 0.4510\n",
      "Batch 434/937, Loss: 0.3910\n",
      "Batch 435/937, Loss: 0.2677\n",
      "Batch 436/937, Loss: 0.3260\n",
      "Batch 437/937, Loss: 0.2710\n",
      "Batch 438/937, Loss: 0.3322\n",
      "Batch 439/937, Loss: 0.4840\n",
      "Batch 440/937, Loss: 0.3409\n",
      "Batch 441/937, Loss: 0.6015\n",
      "Batch 442/937, Loss: 0.3683\n",
      "Batch 443/937, Loss: 0.2237\n",
      "Batch 444/937, Loss: 0.2660\n",
      "Batch 445/937, Loss: 0.2795\n",
      "Batch 446/937, Loss: 0.3005\n",
      "Batch 447/937, Loss: 0.4973\n",
      "Batch 448/937, Loss: 0.2878\n",
      "Batch 449/937, Loss: 0.2714\n",
      "Batch 450/937, Loss: 0.2767\n",
      "Batch 451/937, Loss: 0.4825\n",
      "Batch 452/937, Loss: 0.4852\n",
      "Batch 453/937, Loss: 0.3180\n",
      "Batch 454/937, Loss: 0.3361\n",
      "Batch 455/937, Loss: 0.2914\n",
      "Batch 456/937, Loss: 0.2899\n",
      "Batch 457/937, Loss: 0.3107\n",
      "Batch 458/937, Loss: 0.3159\n",
      "Batch 459/937, Loss: 0.3920\n",
      "Batch 460/937, Loss: 0.3539\n",
      "Batch 461/937, Loss: 0.2771\n",
      "Batch 462/937, Loss: 0.1152\n",
      "Batch 463/937, Loss: 0.2280\n",
      "Batch 464/937, Loss: 0.4640\n",
      "Batch 465/937, Loss: 0.3050\n",
      "Batch 466/937, Loss: 0.2626\n",
      "Batch 467/937, Loss: 0.2441\n",
      "Batch 468/937, Loss: 0.1972\n",
      "Batch 469/937, Loss: 0.2832\n",
      "Batch 470/937, Loss: 0.3875\n",
      "Batch 471/937, Loss: 0.1844\n",
      "Batch 472/937, Loss: 0.4564\n",
      "Batch 473/937, Loss: 0.3060\n",
      "Batch 474/937, Loss: 0.2091\n",
      "Batch 475/937, Loss: 0.2320\n",
      "Batch 476/937, Loss: 0.3176\n",
      "Batch 477/937, Loss: 0.2341\n",
      "Batch 478/937, Loss: 0.2764\n",
      "Batch 479/937, Loss: 0.3295\n",
      "Batch 480/937, Loss: 0.2937\n",
      "Batch 481/937, Loss: 0.2820\n",
      "Batch 482/937, Loss: 0.3319\n",
      "Batch 483/937, Loss: 0.3516\n",
      "Batch 484/937, Loss: 0.4513\n",
      "Batch 485/937, Loss: 0.3456\n",
      "Batch 486/937, Loss: 0.2838\n",
      "Batch 487/937, Loss: 0.1774\n",
      "Batch 488/937, Loss: 0.1762\n",
      "Batch 489/937, Loss: 0.2871\n",
      "Batch 490/937, Loss: 0.3965\n",
      "Batch 491/937, Loss: 0.2305\n",
      "Batch 492/937, Loss: 0.1998\n",
      "Batch 493/937, Loss: 0.2603\n",
      "Batch 494/937, Loss: 0.4754\n",
      "Batch 495/937, Loss: 0.2310\n",
      "Batch 496/937, Loss: 0.2372\n",
      "Batch 497/937, Loss: 0.1295\n",
      "Batch 498/937, Loss: 0.4046\n",
      "Batch 499/937, Loss: 0.3273\n",
      "Batch 500/937, Loss: 0.2866\n",
      "Batch 501/937, Loss: 0.3707\n",
      "Batch 502/937, Loss: 0.2632\n",
      "Batch 503/937, Loss: 0.2645\n",
      "Batch 504/937, Loss: 0.3396\n",
      "Batch 505/937, Loss: 0.5050\n",
      "Batch 506/937, Loss: 0.5352\n",
      "Batch 507/937, Loss: 0.3065\n",
      "Batch 508/937, Loss: 0.2567\n",
      "Batch 509/937, Loss: 0.4326\n",
      "Batch 510/937, Loss: 0.1040\n",
      "Batch 511/937, Loss: 0.3392\n",
      "Batch 512/937, Loss: 0.4987\n",
      "Batch 513/937, Loss: 0.3409\n",
      "Batch 514/937, Loss: 0.4901\n",
      "Batch 515/937, Loss: 0.4383\n",
      "Batch 516/937, Loss: 0.2013\n",
      "Batch 517/937, Loss: 0.3187\n",
      "Batch 518/937, Loss: 0.2286\n",
      "Batch 519/937, Loss: 0.1620\n",
      "Batch 520/937, Loss: 0.2263\n",
      "Batch 521/937, Loss: 0.2111\n",
      "Batch 522/937, Loss: 0.3242\n",
      "Batch 523/937, Loss: 0.2508\n",
      "Batch 524/937, Loss: 0.2677\n",
      "Batch 525/937, Loss: 0.4222\n",
      "Batch 526/937, Loss: 0.2304\n",
      "Batch 527/937, Loss: 0.4301\n",
      "Batch 528/937, Loss: 0.4213\n",
      "Batch 529/937, Loss: 0.2324\n",
      "Batch 530/937, Loss: 0.2496\n",
      "Batch 531/937, Loss: 0.3734\n",
      "Batch 532/937, Loss: 0.3116\n",
      "Batch 533/937, Loss: 0.4028\n",
      "Batch 534/937, Loss: 0.1437\n",
      "Batch 535/937, Loss: 0.2965\n",
      "Batch 536/937, Loss: 0.5812\n",
      "Batch 537/937, Loss: 0.3686\n",
      "Batch 538/937, Loss: 0.2418\n",
      "Batch 539/937, Loss: 0.2819\n",
      "Batch 540/937, Loss: 0.2399\n",
      "Batch 541/937, Loss: 0.2474\n",
      "Batch 542/937, Loss: 0.3543\n",
      "Batch 543/937, Loss: 0.4756\n",
      "Batch 544/937, Loss: 0.2199\n",
      "Batch 545/937, Loss: 0.2378\n",
      "Batch 546/937, Loss: 0.4016\n",
      "Batch 547/937, Loss: 0.3298\n",
      "Batch 548/937, Loss: 0.1674\n",
      "Batch 549/937, Loss: 0.2875\n",
      "Batch 550/937, Loss: 0.3205\n",
      "Batch 551/937, Loss: 0.4280\n",
      "Batch 552/937, Loss: 0.4158\n",
      "Batch 553/937, Loss: 0.3856\n",
      "Batch 554/937, Loss: 0.3002\n",
      "Batch 555/937, Loss: 0.3110\n",
      "Batch 556/937, Loss: 0.2654\n",
      "Batch 557/937, Loss: 0.4034\n",
      "Batch 558/937, Loss: 0.2359\n",
      "Batch 559/937, Loss: 0.2872\n",
      "Batch 560/937, Loss: 0.3473\n",
      "Batch 561/937, Loss: 0.4260\n",
      "Batch 562/937, Loss: 0.2919\n",
      "Batch 563/937, Loss: 0.1055\n",
      "Batch 564/937, Loss: 0.2147\n",
      "Batch 565/937, Loss: 0.2667\n",
      "Batch 566/937, Loss: 0.3223\n",
      "Batch 567/937, Loss: 0.3397\n",
      "Batch 568/937, Loss: 0.3115\n",
      "Batch 569/937, Loss: 0.2904\n",
      "Batch 570/937, Loss: 0.4083\n",
      "Batch 571/937, Loss: 0.2511\n",
      "Batch 572/937, Loss: 0.4891\n",
      "Batch 573/937, Loss: 0.1883\n",
      "Batch 574/937, Loss: 0.4194\n",
      "Batch 575/937, Loss: 0.4404\n",
      "Batch 576/937, Loss: 0.2736\n",
      "Batch 577/937, Loss: 0.3744\n",
      "Batch 578/937, Loss: 0.3114\n",
      "Batch 579/937, Loss: 0.2879\n",
      "Batch 580/937, Loss: 0.2468\n",
      "Batch 581/937, Loss: 0.4960\n",
      "Batch 582/937, Loss: 0.1476\n",
      "Batch 583/937, Loss: 0.2742\n",
      "Batch 584/937, Loss: 0.2700\n",
      "Batch 585/937, Loss: 0.3612\n",
      "Batch 586/937, Loss: 0.3089\n",
      "Batch 587/937, Loss: 0.4057\n",
      "Batch 588/937, Loss: 0.3132\n",
      "Batch 589/937, Loss: 0.3602\n",
      "Batch 590/937, Loss: 0.1996\n",
      "Batch 591/937, Loss: 0.3832\n",
      "Batch 592/937, Loss: 0.2680\n",
      "Batch 593/937, Loss: 0.1318\n",
      "Batch 594/937, Loss: 0.2338\n",
      "Batch 595/937, Loss: 0.2441\n",
      "Batch 596/937, Loss: 0.1775\n",
      "Batch 597/937, Loss: 0.1145\n",
      "Batch 598/937, Loss: 0.2780\n",
      "Batch 599/937, Loss: 0.1598\n",
      "Batch 600/937, Loss: 0.3536\n",
      "Batch 601/937, Loss: 0.2506\n",
      "Batch 602/937, Loss: 0.3004\n",
      "Batch 603/937, Loss: 0.2183\n",
      "Batch 604/937, Loss: 0.2822\n",
      "Batch 605/937, Loss: 0.2332\n",
      "Batch 606/937, Loss: 0.2672\n",
      "Batch 607/937, Loss: 0.2934\n",
      "Batch 608/937, Loss: 0.2544\n",
      "Batch 609/937, Loss: 0.3074\n",
      "Batch 610/937, Loss: 0.2711\n",
      "Batch 611/937, Loss: 0.3045\n",
      "Batch 612/937, Loss: 0.3594\n",
      "Batch 613/937, Loss: 0.2797\n",
      "Batch 614/937, Loss: 0.2403\n",
      "Batch 615/937, Loss: 0.2604\n",
      "Batch 616/937, Loss: 0.2909\n",
      "Batch 617/937, Loss: 0.2357\n",
      "Batch 618/937, Loss: 0.3815\n",
      "Batch 619/937, Loss: 0.3493\n",
      "Batch 620/937, Loss: 0.3751\n",
      "Batch 621/937, Loss: 0.2395\n",
      "Batch 622/937, Loss: 0.3316\n",
      "Batch 623/937, Loss: 0.2008\n",
      "Batch 624/937, Loss: 0.5067\n",
      "Batch 625/937, Loss: 0.4854\n",
      "Batch 626/937, Loss: 0.4000\n",
      "Batch 627/937, Loss: 0.2361\n",
      "Batch 628/937, Loss: 0.2554\n",
      "Batch 629/937, Loss: 0.2452\n",
      "Batch 630/937, Loss: 0.2388\n",
      "Batch 631/937, Loss: 0.1551\n",
      "Batch 632/937, Loss: 0.2637\n",
      "Batch 633/937, Loss: 0.2242\n",
      "Batch 634/937, Loss: 0.2305\n",
      "Batch 635/937, Loss: 0.4169\n",
      "Batch 636/937, Loss: 0.2420\n",
      "Batch 637/937, Loss: 0.3158\n",
      "Batch 638/937, Loss: 0.3083\n",
      "Batch 639/937, Loss: 0.2733\n",
      "Batch 640/937, Loss: 0.1624\n",
      "Batch 641/937, Loss: 0.3353\n",
      "Batch 642/937, Loss: 0.4279\n",
      "Batch 643/937, Loss: 0.1973\n",
      "Batch 644/937, Loss: 0.4440\n",
      "Batch 645/937, Loss: 0.4825\n",
      "Batch 646/937, Loss: 0.2505\n",
      "Batch 647/937, Loss: 0.2774\n",
      "Batch 648/937, Loss: 0.4085\n",
      "Batch 649/937, Loss: 0.3323\n",
      "Batch 650/937, Loss: 0.3245\n",
      "Batch 651/937, Loss: 0.3428\n",
      "Batch 652/937, Loss: 0.3030\n",
      "Batch 653/937, Loss: 0.4625\n",
      "Batch 654/937, Loss: 0.2291\n",
      "Batch 655/937, Loss: 0.5308\n",
      "Batch 656/937, Loss: 0.2765\n",
      "Batch 657/937, Loss: 0.3238\n",
      "Batch 658/937, Loss: 0.1794\n",
      "Batch 659/937, Loss: 0.2047\n",
      "Batch 660/937, Loss: 0.3777\n",
      "Batch 661/937, Loss: 0.1571\n",
      "Batch 662/937, Loss: 0.3074\n",
      "Batch 663/937, Loss: 0.3350\n",
      "Batch 664/937, Loss: 0.2082\n",
      "Batch 665/937, Loss: 0.3551\n",
      "Batch 666/937, Loss: 0.2324\n",
      "Batch 667/937, Loss: 0.3262\n",
      "Batch 668/937, Loss: 0.3799\n",
      "Batch 669/937, Loss: 0.3673\n",
      "Batch 670/937, Loss: 0.2446\n",
      "Batch 671/937, Loss: 0.5902\n",
      "Batch 672/937, Loss: 0.3402\n",
      "Batch 673/937, Loss: 0.3573\n",
      "Batch 674/937, Loss: 0.1718\n",
      "Batch 675/937, Loss: 0.2109\n",
      "Batch 676/937, Loss: 0.3479\n",
      "Batch 677/937, Loss: 0.3192\n",
      "Batch 678/937, Loss: 0.2468\n",
      "Batch 679/937, Loss: 0.6397\n",
      "Batch 680/937, Loss: 0.1559\n",
      "Batch 681/937, Loss: 0.2825\n",
      "Batch 682/937, Loss: 0.2404\n",
      "Batch 683/937, Loss: 0.2187\n",
      "Batch 684/937, Loss: 0.2873\n",
      "Batch 685/937, Loss: 0.5371\n",
      "Batch 686/937, Loss: 0.4007\n",
      "Batch 687/937, Loss: 0.1803\n",
      "Batch 688/937, Loss: 0.3467\n",
      "Batch 689/937, Loss: 0.3082\n",
      "Batch 690/937, Loss: 0.2251\n",
      "Batch 691/937, Loss: 0.1394\n",
      "Batch 692/937, Loss: 0.2121\n",
      "Batch 693/937, Loss: 0.1976\n",
      "Batch 694/937, Loss: 0.3483\n",
      "Batch 695/937, Loss: 0.3168\n",
      "Batch 696/937, Loss: 0.3389\n",
      "Batch 697/937, Loss: 0.3622\n",
      "Batch 698/937, Loss: 0.2424\n",
      "Batch 699/937, Loss: 0.3981\n",
      "Batch 700/937, Loss: 0.2294\n",
      "Batch 701/937, Loss: 0.2750\n",
      "Batch 702/937, Loss: 0.4061\n",
      "Batch 703/937, Loss: 0.3988\n",
      "Batch 704/937, Loss: 0.2157\n",
      "Batch 705/937, Loss: 0.3690\n",
      "Batch 706/937, Loss: 0.4086\n",
      "Batch 707/937, Loss: 0.3131\n",
      "Batch 708/937, Loss: 0.2857\n",
      "Batch 709/937, Loss: 0.2106\n",
      "Batch 710/937, Loss: 0.5355\n",
      "Batch 711/937, Loss: 0.2152\n",
      "Batch 712/937, Loss: 0.2497\n",
      "Batch 713/937, Loss: 0.2469\n",
      "Batch 714/937, Loss: 0.2187\n",
      "Batch 715/937, Loss: 0.2504\n",
      "Batch 716/937, Loss: 0.1552\n",
      "Batch 717/937, Loss: 0.3149\n",
      "Batch 718/937, Loss: 0.3185\n",
      "Batch 719/937, Loss: 0.3274\n",
      "Batch 720/937, Loss: 0.2057\n",
      "Batch 721/937, Loss: 0.1789\n",
      "Batch 722/937, Loss: 0.3600\n",
      "Batch 723/937, Loss: 0.1748\n",
      "Batch 724/937, Loss: 0.2085\n",
      "Batch 725/937, Loss: 0.1564\n",
      "Batch 726/937, Loss: 0.2895\n",
      "Batch 727/937, Loss: 0.2458\n",
      "Batch 728/937, Loss: 0.3408\n",
      "Batch 729/937, Loss: 0.2786\n",
      "Batch 730/937, Loss: 0.2366\n",
      "Batch 731/937, Loss: 0.2887\n",
      "Batch 732/937, Loss: 0.3273\n",
      "Batch 733/937, Loss: 0.3303\n",
      "Batch 734/937, Loss: 0.2512\n",
      "Batch 735/937, Loss: 0.2503\n",
      "Batch 736/937, Loss: 0.3548\n",
      "Batch 737/937, Loss: 0.3201\n",
      "Batch 738/937, Loss: 0.3951\n",
      "Batch 739/937, Loss: 0.1802\n",
      "Batch 740/937, Loss: 0.3044\n",
      "Batch 741/937, Loss: 0.4608\n",
      "Batch 742/937, Loss: 0.1298\n",
      "Batch 743/937, Loss: 0.2776\n",
      "Batch 744/937, Loss: 0.2494\n",
      "Batch 745/937, Loss: 0.2731\n",
      "Batch 746/937, Loss: 0.3349\n",
      "Batch 747/937, Loss: 0.2392\n",
      "Batch 748/937, Loss: 0.1776\n",
      "Batch 749/937, Loss: 0.1856\n",
      "Batch 750/937, Loss: 0.2841\n",
      "Batch 751/937, Loss: 0.2227\n",
      "Batch 752/937, Loss: 0.3485\n",
      "Batch 753/937, Loss: 0.2305\n",
      "Batch 754/937, Loss: 0.4903\n",
      "Batch 755/937, Loss: 0.5179\n",
      "Batch 756/937, Loss: 0.2118\n",
      "Batch 757/937, Loss: 0.1303\n",
      "Batch 758/937, Loss: 0.2969\n",
      "Batch 759/937, Loss: 0.0963\n",
      "Batch 760/937, Loss: 0.1646\n",
      "Batch 761/937, Loss: 0.1438\n",
      "Batch 762/937, Loss: 0.5397\n",
      "Batch 763/937, Loss: 0.4347\n",
      "Batch 764/937, Loss: 0.2843\n",
      "Batch 765/937, Loss: 0.2527\n",
      "Batch 766/937, Loss: 0.1850\n",
      "Batch 767/937, Loss: 0.4449\n",
      "Batch 768/937, Loss: 0.2538\n",
      "Batch 769/937, Loss: 0.2317\n",
      "Batch 770/937, Loss: 0.4066\n",
      "Batch 771/937, Loss: 0.2833\n",
      "Batch 772/937, Loss: 0.2370\n",
      "Batch 773/937, Loss: 0.4122\n",
      "Batch 774/937, Loss: 0.3710\n",
      "Batch 775/937, Loss: 0.4334\n",
      "Batch 776/937, Loss: 0.2689\n",
      "Batch 777/937, Loss: 0.3519\n",
      "Batch 778/937, Loss: 0.1901\n",
      "Batch 779/937, Loss: 0.3775\n",
      "Batch 780/937, Loss: 0.4058\n",
      "Batch 781/937, Loss: 0.3238\n",
      "Batch 782/937, Loss: 0.2399\n",
      "Batch 783/937, Loss: 0.2391\n",
      "Batch 784/937, Loss: 0.3844\n",
      "Batch 785/937, Loss: 0.2574\n",
      "Batch 786/937, Loss: 0.2945\n",
      "Batch 787/937, Loss: 0.2991\n",
      "Batch 788/937, Loss: 0.2986\n",
      "Batch 789/937, Loss: 0.2792\n",
      "Batch 790/937, Loss: 0.2008\n",
      "Batch 791/937, Loss: 0.1846\n",
      "Batch 792/937, Loss: 0.2413\n",
      "Batch 793/937, Loss: 0.1366\n",
      "Batch 794/937, Loss: 0.2462\n",
      "Batch 795/937, Loss: 0.3779\n",
      "Batch 796/937, Loss: 0.2996\n",
      "Batch 797/937, Loss: 0.3641\n",
      "Batch 798/937, Loss: 0.2465\n",
      "Batch 799/937, Loss: 0.1556\n",
      "Batch 800/937, Loss: 0.2333\n",
      "Batch 801/937, Loss: 0.1396\n",
      "Batch 802/937, Loss: 0.2005\n",
      "Batch 803/937, Loss: 0.3913\n",
      "Batch 804/937, Loss: 0.1580\n",
      "Batch 805/937, Loss: 0.3401\n",
      "Batch 806/937, Loss: 0.1682\n",
      "Batch 807/937, Loss: 0.1989\n",
      "Batch 808/937, Loss: 0.3878\n",
      "Batch 809/937, Loss: 0.2591\n",
      "Batch 810/937, Loss: 0.4828\n",
      "Batch 811/937, Loss: 0.3044\n",
      "Batch 812/937, Loss: 0.3191\n",
      "Batch 813/937, Loss: 0.2320\n",
      "Batch 814/937, Loss: 0.3401\n",
      "Batch 815/937, Loss: 0.3464\n",
      "Batch 816/937, Loss: 0.2676\n",
      "Batch 817/937, Loss: 0.1025\n",
      "Batch 818/937, Loss: 0.2662\n",
      "Batch 819/937, Loss: 0.3224\n",
      "Batch 820/937, Loss: 0.2378\n",
      "Batch 821/937, Loss: 0.2365\n",
      "Batch 822/937, Loss: 0.2826\n",
      "Batch 823/937, Loss: 0.1760\n",
      "Batch 824/937, Loss: 0.2642\n",
      "Batch 825/937, Loss: 0.2887\n",
      "Batch 826/937, Loss: 0.2168\n",
      "Batch 827/937, Loss: 0.4475\n",
      "Batch 828/937, Loss: 0.1422\n",
      "Batch 829/937, Loss: 0.2743\n",
      "Batch 830/937, Loss: 0.1711\n",
      "Batch 831/937, Loss: 0.1337\n",
      "Batch 832/937, Loss: 0.3086\n",
      "Batch 833/937, Loss: 0.3756\n",
      "Batch 834/937, Loss: 0.1871\n",
      "Batch 835/937, Loss: 0.1893\n",
      "Batch 836/937, Loss: 0.3813\n",
      "Batch 837/937, Loss: 0.3386\n",
      "Batch 838/937, Loss: 0.2211\n",
      "Batch 839/937, Loss: 0.3659\n",
      "Batch 840/937, Loss: 0.2306\n",
      "Batch 841/937, Loss: 0.2788\n",
      "Batch 842/937, Loss: 0.3411\n",
      "Batch 843/937, Loss: 0.2186\n",
      "Batch 844/937, Loss: 0.1920\n",
      "Batch 845/937, Loss: 0.2459\n",
      "Batch 846/937, Loss: 0.2590\n",
      "Batch 847/937, Loss: 0.1918\n",
      "Batch 848/937, Loss: 0.2545\n",
      "Batch 849/937, Loss: 0.0940\n",
      "Batch 850/937, Loss: 0.1742\n",
      "Batch 851/937, Loss: 0.1824\n",
      "Batch 852/937, Loss: 0.3212\n",
      "Batch 853/937, Loss: 0.2751\n",
      "Batch 854/937, Loss: 0.1336\n",
      "Batch 855/937, Loss: 0.2507\n",
      "Batch 856/937, Loss: 0.3269\n",
      "Batch 857/937, Loss: 0.4104\n",
      "Batch 858/937, Loss: 0.1622\n",
      "Batch 859/937, Loss: 0.3483\n",
      "Batch 860/937, Loss: 0.1800\n",
      "Batch 861/937, Loss: 0.1942\n",
      "Batch 862/937, Loss: 0.1623\n",
      "Batch 863/937, Loss: 0.3585\n",
      "Batch 864/937, Loss: 0.2051\n",
      "Batch 865/937, Loss: 0.1386\n",
      "Batch 866/937, Loss: 0.3589\n",
      "Batch 867/937, Loss: 0.1636\n",
      "Batch 868/937, Loss: 0.1785\n",
      "Batch 869/937, Loss: 0.2268\n",
      "Batch 870/937, Loss: 0.1704\n",
      "Batch 871/937, Loss: 0.3844\n",
      "Batch 872/937, Loss: 0.2563\n",
      "Batch 873/937, Loss: 0.3971\n",
      "Batch 874/937, Loss: 0.4574\n",
      "Batch 875/937, Loss: 0.2449\n",
      "Batch 876/937, Loss: 0.2234\n",
      "Batch 877/937, Loss: 0.2086\n",
      "Batch 878/937, Loss: 0.2278\n",
      "Batch 879/937, Loss: 0.3403\n",
      "Batch 880/937, Loss: 0.2606\n",
      "Batch 881/937, Loss: 0.3665\n",
      "Batch 882/937, Loss: 0.2248\n",
      "Batch 883/937, Loss: 0.1325\n",
      "Batch 884/937, Loss: 0.2342\n",
      "Batch 885/937, Loss: 0.1828\n",
      "Batch 886/937, Loss: 0.4936\n",
      "Batch 887/937, Loss: 0.2998\n",
      "Batch 888/937, Loss: 0.2178\n",
      "Batch 889/937, Loss: 0.2744\n",
      "Batch 890/937, Loss: 0.3548\n",
      "Batch 891/937, Loss: 0.3703\n",
      "Batch 892/937, Loss: 0.1377\n",
      "Batch 893/937, Loss: 0.1863\n",
      "Batch 894/937, Loss: 0.2470\n",
      "Batch 895/937, Loss: 0.2208\n",
      "Batch 896/937, Loss: 0.2126\n",
      "Batch 897/937, Loss: 0.2059\n",
      "Batch 898/937, Loss: 0.3150\n",
      "Batch 899/937, Loss: 0.3487\n",
      "Batch 900/937, Loss: 0.2367\n",
      "Batch 901/937, Loss: 0.2332\n",
      "Batch 902/937, Loss: 0.2864\n",
      "Batch 903/937, Loss: 0.3196\n",
      "Batch 904/937, Loss: 0.3979\n",
      "Batch 905/937, Loss: 0.2953\n",
      "Batch 906/937, Loss: 0.3778\n",
      "Batch 907/937, Loss: 0.2594\n",
      "Batch 908/937, Loss: 0.3542\n",
      "Batch 909/937, Loss: 0.2681\n",
      "Batch 910/937, Loss: 0.1377\n",
      "Batch 911/937, Loss: 0.2725\n",
      "Batch 912/937, Loss: 0.2990\n",
      "Batch 913/937, Loss: 0.2246\n",
      "Batch 914/937, Loss: 0.1657\n",
      "Batch 915/937, Loss: 0.2468\n",
      "Batch 916/937, Loss: 0.1420\n",
      "Batch 917/937, Loss: 0.1103\n",
      "Batch 918/937, Loss: 0.4056\n",
      "Batch 919/937, Loss: 0.2411\n",
      "Batch 920/937, Loss: 0.2227\n",
      "Batch 921/937, Loss: 0.1523\n",
      "Batch 922/937, Loss: 0.2138\n",
      "Batch 923/937, Loss: 0.3653\n",
      "Batch 924/937, Loss: 0.2045\n",
      "Batch 925/937, Loss: 0.1679\n",
      "Batch 926/937, Loss: 0.1520\n",
      "Batch 927/937, Loss: 0.1912\n",
      "Batch 928/937, Loss: 0.4229\n",
      "Batch 929/937, Loss: 0.2691\n",
      "Batch 930/937, Loss: 0.3417\n",
      "Batch 931/937, Loss: 0.2649\n",
      "Batch 932/937, Loss: 0.3390\n",
      "Batch 933/937, Loss: 0.1539\n",
      "Batch 934/937, Loss: 0.4545\n",
      "Batch 935/937, Loss: 0.1530\n",
      "Batch 936/937, Loss: 0.1957\n",
      "Batch 937/937, Loss: 0.2686\n",
      "Batch 938/937, Loss: 0.3380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:07<02:29,  7.89s/it, loss=0.435, accuracy=85.38%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1/937, Loss: 0.4593\n",
      "Batch 2/937, Loss: 0.1792\n",
      "Batch 3/937, Loss: 0.2971\n",
      "Batch 4/937, Loss: 0.2022\n",
      "Batch 5/937, Loss: 0.3013\n",
      "Batch 6/937, Loss: 0.1063\n",
      "Batch 7/937, Loss: 0.1482\n",
      "Batch 8/937, Loss: 0.2674\n",
      "Batch 9/937, Loss: 0.0802\n",
      "Batch 10/937, Loss: 0.2339\n",
      "Batch 11/937, Loss: 0.2024\n",
      "Batch 12/937, Loss: 0.2265\n",
      "Batch 13/937, Loss: 0.3560\n",
      "Batch 14/937, Loss: 0.2465\n",
      "Batch 15/937, Loss: 0.2403\n",
      "Batch 16/937, Loss: 0.0868\n",
      "Batch 17/937, Loss: 0.3063\n",
      "Batch 18/937, Loss: 0.1414\n",
      "Batch 19/937, Loss: 0.2446\n",
      "Batch 20/937, Loss: 0.1494\n",
      "Batch 21/937, Loss: 0.3188\n",
      "Batch 22/937, Loss: 0.2992\n",
      "Batch 23/937, Loss: 0.1015\n",
      "Batch 24/937, Loss: 0.1724\n",
      "Batch 25/937, Loss: 0.1505\n",
      "Batch 26/937, Loss: 0.2181\n",
      "Batch 27/937, Loss: 0.2743\n",
      "Batch 28/937, Loss: 0.3514\n",
      "Batch 29/937, Loss: 0.2019\n",
      "Batch 30/937, Loss: 0.3589\n",
      "Batch 31/937, Loss: 0.3152\n",
      "Batch 32/937, Loss: 0.3490\n",
      "Batch 33/937, Loss: 0.2253\n",
      "Batch 34/937, Loss: 0.2422\n",
      "Batch 35/937, Loss: 0.1157\n",
      "Batch 36/937, Loss: 0.2195\n",
      "Batch 37/937, Loss: 0.2850\n",
      "Batch 38/937, Loss: 0.1549\n",
      "Batch 39/937, Loss: 0.2330\n",
      "Batch 40/937, Loss: 0.1707\n",
      "Batch 41/937, Loss: 0.1735\n",
      "Batch 42/937, Loss: 0.3987\n",
      "Batch 43/937, Loss: 0.1327\n",
      "Batch 44/937, Loss: 0.2076\n",
      "Batch 45/937, Loss: 0.4076\n",
      "Batch 46/937, Loss: 0.1639\n",
      "Batch 47/937, Loss: 0.4257\n",
      "Batch 48/937, Loss: 0.1762\n",
      "Batch 49/937, Loss: 0.3585\n",
      "Batch 50/937, Loss: 0.2593\n",
      "Batch 51/937, Loss: 0.3119\n",
      "Batch 52/937, Loss: 0.3205\n",
      "Batch 53/937, Loss: 0.3186\n",
      "Batch 54/937, Loss: 0.4014\n",
      "Batch 55/937, Loss: 0.2529\n",
      "Batch 56/937, Loss: 0.1548\n",
      "Batch 57/937, Loss: 0.2102\n",
      "Batch 58/937, Loss: 0.1389\n",
      "Batch 59/937, Loss: 0.1877\n",
      "Batch 60/937, Loss: 0.2451\n",
      "Batch 61/937, Loss: 0.1039\n",
      "Batch 62/937, Loss: 0.2172\n",
      "Batch 63/937, Loss: 0.2852\n",
      "Batch 64/937, Loss: 0.1393\n",
      "Batch 65/937, Loss: 0.0737\n",
      "Batch 66/937, Loss: 0.2480\n",
      "Batch 67/937, Loss: 0.2219\n",
      "Batch 68/937, Loss: 0.2733\n",
      "Batch 69/937, Loss: 0.2506\n",
      "Batch 70/937, Loss: 0.1424\n",
      "Batch 71/937, Loss: 0.3545\n",
      "Batch 72/937, Loss: 0.3319\n",
      "Batch 73/937, Loss: 0.2285\n",
      "Batch 74/937, Loss: 0.1709\n",
      "Batch 75/937, Loss: 0.1926\n",
      "Batch 76/937, Loss: 0.2242\n",
      "Batch 77/937, Loss: 0.1704\n",
      "Batch 78/937, Loss: 0.3542\n",
      "Batch 79/937, Loss: 0.2747\n",
      "Batch 80/937, Loss: 0.2032\n",
      "Batch 81/937, Loss: 0.3641\n",
      "Batch 82/937, Loss: 0.3587\n",
      "Batch 83/937, Loss: 0.3207\n",
      "Batch 84/937, Loss: 0.2626\n",
      "Batch 85/937, Loss: 0.3052\n",
      "Batch 86/937, Loss: 0.2580\n",
      "Batch 87/937, Loss: 0.3007\n",
      "Batch 88/937, Loss: 0.2821\n",
      "Batch 89/937, Loss: 0.3045\n",
      "Batch 90/937, Loss: 0.1934\n",
      "Batch 91/937, Loss: 0.1870\n",
      "Batch 92/937, Loss: 0.1668\n",
      "Batch 93/937, Loss: 0.3170\n",
      "Batch 94/937, Loss: 0.3107\n",
      "Batch 95/937, Loss: 0.1482\n",
      "Batch 96/937, Loss: 0.2249\n",
      "Batch 97/937, Loss: 0.4434\n",
      "Batch 98/937, Loss: 0.1815\n",
      "Batch 99/937, Loss: 0.2624\n",
      "Batch 100/937, Loss: 0.2422\n",
      "Batch 101/937, Loss: 0.2469\n",
      "Batch 102/937, Loss: 0.3230\n",
      "Batch 103/937, Loss: 0.2937\n",
      "Batch 104/937, Loss: 0.2025\n",
      "Batch 105/937, Loss: 0.1237\n",
      "Batch 106/937, Loss: 0.2157\n",
      "Batch 107/937, Loss: 0.2536\n",
      "Batch 108/937, Loss: 0.2873\n",
      "Batch 109/937, Loss: 0.2118\n",
      "Batch 110/937, Loss: 0.3088\n",
      "Batch 111/937, Loss: 0.3375\n",
      "Batch 112/937, Loss: 0.2168\n",
      "Batch 113/937, Loss: 0.2509\n",
      "Batch 114/937, Loss: 0.2035\n",
      "Batch 115/937, Loss: 0.0728\n",
      "Batch 116/937, Loss: 0.1918\n",
      "Batch 117/937, Loss: 0.2996\n",
      "Batch 118/937, Loss: 0.1681\n",
      "Batch 119/937, Loss: 0.3134\n",
      "Batch 120/937, Loss: 0.1428\n",
      "Batch 121/937, Loss: 0.1163\n",
      "Batch 122/937, Loss: 0.1672\n",
      "Batch 123/937, Loss: 0.1858\n",
      "Batch 124/937, Loss: 0.1674\n",
      "Batch 125/937, Loss: 0.2574\n",
      "Batch 126/937, Loss: 0.1612\n",
      "Batch 127/937, Loss: 0.1529\n",
      "Batch 128/937, Loss: 0.2136\n",
      "Batch 129/937, Loss: 0.2449\n",
      "Batch 130/937, Loss: 0.2757\n",
      "Batch 131/937, Loss: 0.3045\n",
      "Batch 132/937, Loss: 0.2967\n",
      "Batch 133/937, Loss: 0.1296\n",
      "Batch 134/937, Loss: 0.1318\n",
      "Batch 135/937, Loss: 0.2816\n",
      "Batch 136/937, Loss: 0.1277\n",
      "Batch 137/937, Loss: 0.2870\n",
      "Batch 138/937, Loss: 0.3098\n",
      "Batch 139/937, Loss: 0.2067\n",
      "Batch 140/937, Loss: 0.2857\n",
      "Batch 141/937, Loss: 0.2693\n",
      "Batch 142/937, Loss: 0.2849\n",
      "Batch 143/937, Loss: 0.3412\n",
      "Batch 144/937, Loss: 0.1826\n",
      "Batch 145/937, Loss: 0.1114\n",
      "Batch 146/937, Loss: 0.1356\n",
      "Batch 147/937, Loss: 0.2433\n",
      "Batch 148/937, Loss: 0.2579\n",
      "Batch 149/937, Loss: 0.3213\n",
      "Batch 150/937, Loss: 0.2089\n",
      "Batch 151/937, Loss: 0.2200\n",
      "Batch 152/937, Loss: 0.1436\n",
      "Batch 153/937, Loss: 0.1634\n",
      "Batch 154/937, Loss: 0.2943\n",
      "Batch 155/937, Loss: 0.2152\n",
      "Batch 156/937, Loss: 0.2318\n",
      "Batch 157/937, Loss: 0.1599\n",
      "Batch 158/937, Loss: 0.2182\n",
      "Batch 159/937, Loss: 0.2630\n",
      "Batch 160/937, Loss: 0.3067\n",
      "Batch 161/937, Loss: 0.2305\n",
      "Batch 162/937, Loss: 0.2964\n",
      "Batch 163/937, Loss: 0.4487\n",
      "Batch 164/937, Loss: 0.2192\n",
      "Batch 165/937, Loss: 0.0987\n",
      "Batch 166/937, Loss: 0.1875\n",
      "Batch 167/937, Loss: 0.1222\n",
      "Batch 168/937, Loss: 0.4546\n",
      "Batch 169/937, Loss: 0.1826\n",
      "Batch 170/937, Loss: 0.2485\n",
      "Batch 171/937, Loss: 0.2674\n",
      "Batch 172/937, Loss: 0.2106\n",
      "Batch 173/937, Loss: 0.1937\n",
      "Batch 174/937, Loss: 0.1246\n",
      "Batch 175/937, Loss: 0.4619\n",
      "Batch 176/937, Loss: 0.3256\n",
      "Batch 177/937, Loss: 0.1220\n",
      "Batch 178/937, Loss: 0.2883\n",
      "Batch 179/937, Loss: 0.2618\n",
      "Batch 180/937, Loss: 0.3070\n",
      "Batch 181/937, Loss: 0.2678\n",
      "Batch 182/937, Loss: 0.1019\n",
      "Batch 183/937, Loss: 0.1340\n",
      "Batch 184/937, Loss: 0.1910\n",
      "Batch 185/937, Loss: 0.1815\n",
      "Batch 186/937, Loss: 0.2966\n",
      "Batch 187/937, Loss: 0.3285\n",
      "Batch 188/937, Loss: 0.1389\n",
      "Batch 189/937, Loss: 0.3532\n",
      "Batch 190/937, Loss: 0.1957\n",
      "Batch 191/937, Loss: 0.3532\n",
      "Batch 192/937, Loss: 0.2975\n",
      "Batch 193/937, Loss: 0.3014\n",
      "Batch 194/937, Loss: 0.2855\n",
      "Batch 195/937, Loss: 0.3500\n",
      "Batch 196/937, Loss: 0.2430\n",
      "Batch 197/937, Loss: 0.2382\n",
      "Batch 198/937, Loss: 0.1016\n",
      "Batch 199/937, Loss: 0.3144\n",
      "Batch 200/937, Loss: 0.2288\n",
      "Batch 201/937, Loss: 0.1597\n",
      "Batch 202/937, Loss: 0.1787\n",
      "Batch 203/937, Loss: 0.2215\n",
      "Batch 204/937, Loss: 0.1866\n",
      "Batch 205/937, Loss: 0.1969\n",
      "Batch 206/937, Loss: 0.1287\n",
      "Batch 207/937, Loss: 0.2198\n",
      "Batch 208/937, Loss: 0.2502\n",
      "Batch 209/937, Loss: 0.1497\n",
      "Batch 210/937, Loss: 0.2573\n",
      "Batch 211/937, Loss: 0.4468\n",
      "Batch 212/937, Loss: 0.2711\n",
      "Batch 213/937, Loss: 0.3202\n",
      "Batch 214/937, Loss: 0.1288\n",
      "Batch 215/937, Loss: 0.1661\n",
      "Batch 216/937, Loss: 0.2065\n",
      "Batch 217/937, Loss: 0.2185\n",
      "Batch 218/937, Loss: 0.2241\n",
      "Batch 219/937, Loss: 0.1640\n",
      "Batch 220/937, Loss: 0.2700\n",
      "Batch 221/937, Loss: 0.2363\n",
      "Batch 222/937, Loss: 0.2101\n",
      "Batch 223/937, Loss: 0.2314\n",
      "Batch 224/937, Loss: 0.1536\n",
      "Batch 225/937, Loss: 0.0913\n",
      "Batch 226/937, Loss: 0.1964\n",
      "Batch 227/937, Loss: 0.2690\n",
      "Batch 228/937, Loss: 0.1343\n",
      "Batch 229/937, Loss: 0.2382\n",
      "Batch 230/937, Loss: 0.2385\n",
      "Batch 231/937, Loss: 0.2027\n",
      "Batch 232/937, Loss: 0.0880\n",
      "Batch 233/937, Loss: 0.2441\n",
      "Batch 234/937, Loss: 0.1815\n",
      "Batch 235/937, Loss: 0.2270\n",
      "Batch 236/937, Loss: 0.0994\n",
      "Batch 237/937, Loss: 0.1513\n",
      "Batch 238/937, Loss: 0.3056\n",
      "Batch 239/937, Loss: 0.1335\n",
      "Batch 240/937, Loss: 0.1842\n",
      "Batch 241/937, Loss: 0.1816\n",
      "Batch 242/937, Loss: 0.2361\n",
      "Batch 243/937, Loss: 0.1618\n",
      "Batch 244/937, Loss: 0.0827\n",
      "Batch 245/937, Loss: 0.2068\n",
      "Batch 246/937, Loss: 0.1838\n",
      "Batch 247/937, Loss: 0.2556\n",
      "Batch 248/937, Loss: 0.3281\n",
      "Batch 249/937, Loss: 0.2075\n",
      "Batch 250/937, Loss: 0.1458\n",
      "Batch 251/937, Loss: 0.1805\n",
      "Batch 252/937, Loss: 0.2284\n",
      "Batch 253/937, Loss: 0.1430\n",
      "Batch 254/937, Loss: 0.2285\n",
      "Batch 255/937, Loss: 0.2330\n",
      "Batch 256/937, Loss: 0.3908\n",
      "Batch 257/937, Loss: 0.1951\n",
      "Batch 258/937, Loss: 0.2600\n",
      "Batch 259/937, Loss: 0.0882\n",
      "Batch 260/937, Loss: 0.2447\n",
      "Batch 261/937, Loss: 0.2924\n",
      "Batch 262/937, Loss: 0.2179\n",
      "Batch 263/937, Loss: 0.4241\n",
      "Batch 264/937, Loss: 0.1108\n",
      "Batch 265/937, Loss: 0.1803\n",
      "Batch 266/937, Loss: 0.2487\n",
      "Batch 267/937, Loss: 0.3927\n",
      "Batch 268/937, Loss: 0.2597\n",
      "Batch 269/937, Loss: 0.1466\n",
      "Batch 270/937, Loss: 0.2759\n",
      "Batch 271/937, Loss: 0.1509\n",
      "Batch 272/937, Loss: 0.0897\n",
      "Batch 273/937, Loss: 0.1171\n",
      "Batch 274/937, Loss: 0.1961\n",
      "Batch 275/937, Loss: 0.1398\n",
      "Batch 276/937, Loss: 0.2051\n",
      "Batch 277/937, Loss: 0.0806\n",
      "Batch 278/937, Loss: 0.2481\n",
      "Batch 279/937, Loss: 0.1115\n",
      "Batch 280/937, Loss: 0.2889\n",
      "Batch 281/937, Loss: 0.2995\n",
      "Batch 282/937, Loss: 0.2904\n",
      "Batch 283/937, Loss: 0.2432\n",
      "Batch 284/937, Loss: 0.2902\n",
      "Batch 285/937, Loss: 0.1633\n",
      "Batch 286/937, Loss: 0.2573\n",
      "Batch 287/937, Loss: 0.3651\n",
      "Batch 288/937, Loss: 0.3322\n",
      "Batch 289/937, Loss: 0.2725\n",
      "Batch 290/937, Loss: 0.3068\n",
      "Batch 291/937, Loss: 0.3372\n",
      "Batch 292/937, Loss: 0.2017\n",
      "Batch 293/937, Loss: 0.3148\n",
      "Batch 294/937, Loss: 0.2274\n",
      "Batch 295/937, Loss: 0.1522\n",
      "Batch 296/937, Loss: 0.1737\n",
      "Batch 297/937, Loss: 0.1821\n",
      "Batch 298/937, Loss: 0.1630\n",
      "Batch 299/937, Loss: 0.3207\n",
      "Batch 300/937, Loss: 0.2126\n",
      "Batch 301/937, Loss: 0.1947\n",
      "Batch 302/937, Loss: 0.1833\n",
      "Batch 303/937, Loss: 0.1368\n",
      "Batch 304/937, Loss: 0.1150\n",
      "Batch 305/937, Loss: 0.3252\n",
      "Batch 306/937, Loss: 0.1571\n",
      "Batch 307/937, Loss: 0.2868\n",
      "Batch 308/937, Loss: 0.1781\n",
      "Batch 309/937, Loss: 0.2947\n",
      "Batch 310/937, Loss: 0.1236\n",
      "Batch 311/937, Loss: 0.2276\n",
      "Batch 312/937, Loss: 0.1966\n",
      "Batch 313/937, Loss: 0.3404\n",
      "Batch 314/937, Loss: 0.1107\n",
      "Batch 315/937, Loss: 0.3343\n",
      "Batch 316/937, Loss: 0.3711\n",
      "Batch 317/937, Loss: 0.1005\n",
      "Batch 318/937, Loss: 0.3238\n",
      "Batch 319/937, Loss: 0.2339\n",
      "Batch 320/937, Loss: 0.2388\n",
      "Batch 321/937, Loss: 0.2284\n",
      "Batch 322/937, Loss: 0.1231\n",
      "Batch 323/937, Loss: 0.1843\n",
      "Batch 324/937, Loss: 0.3067\n",
      "Batch 325/937, Loss: 0.2267\n",
      "Batch 326/937, Loss: 0.2209\n",
      "Batch 327/937, Loss: 0.1976\n",
      "Batch 328/937, Loss: 0.2746\n",
      "Batch 329/937, Loss: 0.1111\n",
      "Batch 330/937, Loss: 0.3092\n",
      "Batch 331/937, Loss: 0.1861\n",
      "Batch 332/937, Loss: 0.1521\n",
      "Batch 333/937, Loss: 0.2666\n",
      "Batch 334/937, Loss: 0.1423\n",
      "Batch 335/937, Loss: 0.2112\n",
      "Batch 336/937, Loss: 0.2232\n",
      "Batch 337/937, Loss: 0.3457\n",
      "Batch 338/937, Loss: 0.3032\n",
      "Batch 339/937, Loss: 0.2657\n",
      "Batch 340/937, Loss: 0.2171\n",
      "Batch 341/937, Loss: 0.2151\n",
      "Batch 342/937, Loss: 0.2228\n",
      "Batch 343/937, Loss: 0.3676\n",
      "Batch 344/937, Loss: 0.2172\n",
      "Batch 345/937, Loss: 0.2534\n",
      "Batch 346/937, Loss: 0.3486\n",
      "Batch 347/937, Loss: 0.2633\n",
      "Batch 348/937, Loss: 0.2440\n",
      "Batch 349/937, Loss: 0.2651\n",
      "Batch 350/937, Loss: 0.1882\n",
      "Batch 351/937, Loss: 0.1875\n",
      "Batch 352/937, Loss: 0.1215\n",
      "Batch 353/937, Loss: 0.1388\n",
      "Batch 354/937, Loss: 0.3635\n",
      "Batch 355/937, Loss: 0.1487\n",
      "Batch 356/937, Loss: 0.3034\n",
      "Batch 357/937, Loss: 0.1709\n",
      "Batch 358/937, Loss: 0.2559\n",
      "Batch 359/937, Loss: 0.1751\n",
      "Batch 360/937, Loss: 0.1841\n",
      "Batch 361/937, Loss: 0.1897\n",
      "Batch 362/937, Loss: 0.2015\n",
      "Batch 363/937, Loss: 0.1610\n",
      "Batch 364/937, Loss: 0.2326\n",
      "Batch 365/937, Loss: 0.3091\n",
      "Batch 366/937, Loss: 0.3682\n",
      "Batch 367/937, Loss: 0.2062\n",
      "Batch 368/937, Loss: 0.2898\n",
      "Batch 369/937, Loss: 0.1555\n",
      "Batch 370/937, Loss: 0.3993\n",
      "Batch 371/937, Loss: 0.1363\n",
      "Batch 372/937, Loss: 0.1070\n",
      "Batch 373/937, Loss: 0.1664\n",
      "Batch 374/937, Loss: 0.0595\n",
      "Batch 375/937, Loss: 0.1430\n",
      "Batch 376/937, Loss: 0.1278\n",
      "Batch 377/937, Loss: 0.3105\n",
      "Batch 378/937, Loss: 0.1096\n",
      "Batch 379/937, Loss: 0.2520\n",
      "Batch 380/937, Loss: 0.2753\n",
      "Batch 381/937, Loss: 0.2337\n",
      "Batch 382/937, Loss: 0.2915\n",
      "Batch 383/937, Loss: 0.3368\n",
      "Batch 384/937, Loss: 0.3398\n",
      "Batch 385/937, Loss: 0.2453\n",
      "Batch 386/937, Loss: 0.2951\n",
      "Batch 387/937, Loss: 0.1996\n",
      "Batch 388/937, Loss: 0.1012\n",
      "Batch 389/937, Loss: 0.1438\n",
      "Batch 390/937, Loss: 0.1201\n",
      "Batch 391/937, Loss: 0.1229\n",
      "Batch 392/937, Loss: 0.1863\n",
      "Batch 393/937, Loss: 0.1474\n",
      "Batch 394/937, Loss: 0.1474\n",
      "Batch 395/937, Loss: 0.3304\n",
      "Batch 396/937, Loss: 0.1569\n",
      "Batch 397/937, Loss: 0.2008\n",
      "Batch 398/937, Loss: 0.1974\n",
      "Batch 399/937, Loss: 0.1328\n",
      "Batch 400/937, Loss: 0.2216\n",
      "Batch 401/937, Loss: 0.2586\n",
      "Batch 402/937, Loss: 0.1469\n",
      "Batch 403/937, Loss: 0.2406\n",
      "Batch 404/937, Loss: 0.1401\n",
      "Batch 405/937, Loss: 0.0786\n",
      "Batch 406/937, Loss: 0.1573\n",
      "Batch 407/937, Loss: 0.2279\n",
      "Batch 408/937, Loss: 0.3111\n",
      "Batch 409/937, Loss: 0.1353\n",
      "Batch 410/937, Loss: 0.1478\n",
      "Batch 411/937, Loss: 0.1042\n",
      "Batch 412/937, Loss: 0.0999\n",
      "Batch 413/937, Loss: 0.1807\n",
      "Batch 414/937, Loss: 0.2699\n",
      "Batch 415/937, Loss: 0.0830\n",
      "Batch 416/937, Loss: 0.1583\n",
      "Batch 417/937, Loss: 0.1411\n",
      "Batch 418/937, Loss: 0.1370\n",
      "Batch 419/937, Loss: 0.1392\n",
      "Batch 420/937, Loss: 0.1116\n",
      "Batch 421/937, Loss: 0.1701\n",
      "Batch 422/937, Loss: 0.1715\n",
      "Batch 423/937, Loss: 0.1985\n",
      "Batch 424/937, Loss: 0.3725\n",
      "Batch 425/937, Loss: 0.2354\n",
      "Batch 426/937, Loss: 0.1367\n",
      "Batch 427/937, Loss: 0.2814\n",
      "Batch 428/937, Loss: 0.3227\n",
      "Batch 429/937, Loss: 0.2274\n",
      "Batch 430/937, Loss: 0.0460\n",
      "Batch 431/937, Loss: 0.2683\n",
      "Batch 432/937, Loss: 0.2937\n",
      "Batch 433/937, Loss: 0.0992\n",
      "Batch 434/937, Loss: 0.2514\n",
      "Batch 435/937, Loss: 0.3346\n",
      "Batch 436/937, Loss: 0.3117\n",
      "Batch 437/937, Loss: 0.2318\n",
      "Batch 438/937, Loss: 0.2544\n",
      "Batch 439/937, Loss: 0.2114\n",
      "Batch 440/937, Loss: 0.0953\n",
      "Batch 441/937, Loss: 0.0996\n",
      "Batch 442/937, Loss: 0.2788\n",
      "Batch 443/937, Loss: 0.2816\n",
      "Batch 444/937, Loss: 0.2047\n",
      "Batch 445/937, Loss: 0.3389\n",
      "Batch 446/937, Loss: 0.1432\n",
      "Batch 447/937, Loss: 0.2509\n",
      "Batch 448/937, Loss: 0.2177\n",
      "Batch 449/937, Loss: 0.1563\n",
      "Batch 450/937, Loss: 0.2874\n",
      "Batch 451/937, Loss: 0.3643\n",
      "Batch 452/937, Loss: 0.2241\n",
      "Batch 453/937, Loss: 0.1264\n",
      "Batch 454/937, Loss: 0.1661\n",
      "Batch 455/937, Loss: 0.2706\n",
      "Batch 456/937, Loss: 0.2525\n",
      "Batch 457/937, Loss: 0.1292\n",
      "Batch 458/937, Loss: 0.1388\n",
      "Batch 459/937, Loss: 0.2209\n",
      "Batch 460/937, Loss: 0.2378\n",
      "Batch 461/937, Loss: 0.2034\n",
      "Batch 462/937, Loss: 0.1413\n",
      "Batch 463/937, Loss: 0.1712\n",
      "Batch 464/937, Loss: 0.1314\n",
      "Batch 465/937, Loss: 0.0779\n",
      "Batch 466/937, Loss: 0.2179\n",
      "Batch 467/937, Loss: 0.2740\n",
      "Batch 468/937, Loss: 0.1374\n",
      "Batch 469/937, Loss: 0.0783\n",
      "Batch 470/937, Loss: 0.2054\n",
      "Batch 471/937, Loss: 0.1359\n",
      "Batch 472/937, Loss: 0.2748\n",
      "Batch 473/937, Loss: 0.2130\n",
      "Batch 474/937, Loss: 0.2863\n",
      "Batch 475/937, Loss: 0.1634\n",
      "Batch 476/937, Loss: 0.2114\n",
      "Batch 477/937, Loss: 0.1017\n",
      "Batch 478/937, Loss: 0.1289\n",
      "Batch 479/937, Loss: 0.4120\n",
      "Batch 480/937, Loss: 0.1543\n",
      "Batch 481/937, Loss: 0.2376\n",
      "Batch 482/937, Loss: 0.2475\n",
      "Batch 483/937, Loss: 0.1352\n",
      "Batch 484/937, Loss: 0.2864\n",
      "Batch 485/937, Loss: 0.3007\n",
      "Batch 486/937, Loss: 0.1925\n",
      "Batch 487/937, Loss: 0.2579\n",
      "Batch 488/937, Loss: 0.1608\n",
      "Batch 489/937, Loss: 0.1183\n",
      "Batch 490/937, Loss: 0.1344\n",
      "Batch 491/937, Loss: 0.2031\n",
      "Batch 492/937, Loss: 0.2874\n",
      "Batch 493/937, Loss: 0.2854\n",
      "Batch 494/937, Loss: 0.1905\n",
      "Batch 495/937, Loss: 0.1025\n",
      "Batch 496/937, Loss: 0.1612\n",
      "Batch 497/937, Loss: 0.2566\n",
      "Batch 498/937, Loss: 0.2697\n",
      "Batch 499/937, Loss: 0.2058\n",
      "Batch 500/937, Loss: 0.2201\n",
      "Batch 501/937, Loss: 0.2475\n",
      "Batch 502/937, Loss: 0.2432\n",
      "Batch 503/937, Loss: 0.3109\n",
      "Batch 504/937, Loss: 0.2034\n",
      "Batch 505/937, Loss: 0.2684\n",
      "Batch 506/937, Loss: 0.1394\n",
      "Batch 507/937, Loss: 0.3348\n",
      "Batch 508/937, Loss: 0.1727\n",
      "Batch 509/937, Loss: 0.1769\n",
      "Batch 510/937, Loss: 0.2985\n",
      "Batch 511/937, Loss: 0.2590\n",
      "Batch 512/937, Loss: 0.2167\n",
      "Batch 513/937, Loss: 0.1401\n",
      "Batch 514/937, Loss: 0.1339\n",
      "Batch 515/937, Loss: 0.1110\n",
      "Batch 516/937, Loss: 0.2825\n",
      "Batch 517/937, Loss: 0.2137\n",
      "Batch 518/937, Loss: 0.3542\n",
      "Batch 519/937, Loss: 0.2106\n",
      "Batch 520/937, Loss: 0.2470\n",
      "Batch 521/937, Loss: 0.1240\n",
      "Batch 522/937, Loss: 0.4401\n",
      "Batch 523/937, Loss: 0.1299\n",
      "Batch 524/937, Loss: 0.1536\n",
      "Batch 525/937, Loss: 0.0963\n",
      "Batch 526/937, Loss: 0.1478\n",
      "Batch 527/937, Loss: 0.2027\n",
      "Batch 528/937, Loss: 0.2362\n",
      "Batch 529/937, Loss: 0.2559\n",
      "Batch 530/937, Loss: 0.2833\n",
      "Batch 531/937, Loss: 0.1234\n",
      "Batch 532/937, Loss: 0.4513\n",
      "Batch 533/937, Loss: 0.1480\n",
      "Batch 534/937, Loss: 0.2215\n",
      "Batch 535/937, Loss: 0.1887\n",
      "Batch 536/937, Loss: 0.2700\n",
      "Batch 537/937, Loss: 0.5850\n",
      "Batch 538/937, Loss: 0.1619\n",
      "Batch 539/937, Loss: 0.0967\n",
      "Batch 540/937, Loss: 0.2751\n",
      "Batch 541/937, Loss: 0.3357\n",
      "Batch 542/937, Loss: 0.2386\n",
      "Batch 543/937, Loss: 0.2765\n",
      "Batch 544/937, Loss: 0.2903\n",
      "Batch 545/937, Loss: 0.1198\n",
      "Batch 546/937, Loss: 0.3469\n",
      "Batch 547/937, Loss: 0.1017\n",
      "Batch 548/937, Loss: 0.1731\n",
      "Batch 549/937, Loss: 0.1839\n",
      "Batch 550/937, Loss: 0.2681\n",
      "Batch 551/937, Loss: 0.2635\n",
      "Batch 552/937, Loss: 0.2013\n",
      "Batch 553/937, Loss: 0.1327\n",
      "Batch 554/937, Loss: 0.0905\n",
      "Batch 555/937, Loss: 0.2365\n",
      "Batch 556/937, Loss: 0.1619\n",
      "Batch 557/937, Loss: 0.2335\n",
      "Batch 558/937, Loss: 0.1448\n",
      "Batch 559/937, Loss: 0.2038\n",
      "Batch 560/937, Loss: 0.3367\n",
      "Batch 561/937, Loss: 0.3020\n",
      "Batch 562/937, Loss: 0.2765\n",
      "Batch 563/937, Loss: 0.0651\n",
      "Batch 564/937, Loss: 0.1779\n",
      "Batch 565/937, Loss: 0.2976\n",
      "Batch 566/937, Loss: 0.1875\n",
      "Batch 567/937, Loss: 0.2143\n",
      "Batch 568/937, Loss: 0.2515\n",
      "Batch 569/937, Loss: 0.2009\n",
      "Batch 570/937, Loss: 0.2291\n",
      "Batch 571/937, Loss: 0.1218\n",
      "Batch 572/937, Loss: 0.2503\n",
      "Batch 573/937, Loss: 0.2208\n",
      "Batch 574/937, Loss: 0.0715\n",
      "Batch 575/937, Loss: 0.2150\n",
      "Batch 576/937, Loss: 0.2101\n",
      "Batch 577/937, Loss: 0.1515\n",
      "Batch 578/937, Loss: 0.1734\n",
      "Batch 579/937, Loss: 0.0888\n",
      "Batch 580/937, Loss: 0.0855\n",
      "Batch 581/937, Loss: 0.2339\n",
      "Batch 582/937, Loss: 0.1695\n",
      "Batch 583/937, Loss: 0.3302\n",
      "Batch 584/937, Loss: 0.1318\n",
      "Batch 585/937, Loss: 0.2415\n",
      "Batch 586/937, Loss: 0.2303\n",
      "Batch 587/937, Loss: 0.2137\n",
      "Batch 588/937, Loss: 0.1300\n",
      "Batch 589/937, Loss: 0.0828\n",
      "Batch 590/937, Loss: 0.3028\n",
      "Batch 591/937, Loss: 0.1984\n",
      "Batch 592/937, Loss: 0.2175\n",
      "Batch 593/937, Loss: 0.2704\n",
      "Batch 594/937, Loss: 0.2284\n",
      "Batch 595/937, Loss: 0.1454\n",
      "Batch 596/937, Loss: 0.1779\n",
      "Batch 597/937, Loss: 0.2823\n",
      "Batch 598/937, Loss: 0.3753\n",
      "Batch 599/937, Loss: 0.1990\n",
      "Batch 600/937, Loss: 0.1666\n",
      "Batch 601/937, Loss: 0.1666\n",
      "Batch 602/937, Loss: 0.2161\n",
      "Batch 603/937, Loss: 0.2245\n",
      "Batch 604/937, Loss: 0.3660\n",
      "Batch 605/937, Loss: 0.3126\n",
      "Batch 606/937, Loss: 0.0905\n",
      "Batch 607/937, Loss: 0.2080\n",
      "Batch 608/937, Loss: 0.1597\n",
      "Batch 609/937, Loss: 0.3475\n",
      "Batch 610/937, Loss: 0.3220\n",
      "Batch 611/937, Loss: 0.0661\n",
      "Batch 612/937, Loss: 0.1686\n",
      "Batch 613/937, Loss: 0.2799\n",
      "Batch 614/937, Loss: 0.1607\n",
      "Batch 615/937, Loss: 0.1436\n",
      "Batch 616/937, Loss: 0.3055\n",
      "Batch 617/937, Loss: 0.0644\n",
      "Batch 618/937, Loss: 0.2697\n",
      "Batch 619/937, Loss: 0.2070\n",
      "Batch 620/937, Loss: 0.2124\n",
      "Batch 621/937, Loss: 0.0919\n",
      "Batch 622/937, Loss: 0.0965\n",
      "Batch 623/937, Loss: 0.1497\n",
      "Batch 624/937, Loss: 0.1003\n",
      "Batch 625/937, Loss: 0.2274\n",
      "Batch 626/937, Loss: 0.0872\n",
      "Batch 627/937, Loss: 0.2269\n",
      "Batch 628/937, Loss: 0.3634\n",
      "Batch 629/937, Loss: 0.1947\n",
      "Batch 630/937, Loss: 0.1713\n",
      "Batch 631/937, Loss: 0.3015\n",
      "Batch 632/937, Loss: 0.1946\n",
      "Batch 633/937, Loss: 0.1678\n",
      "Batch 634/937, Loss: 0.2435\n",
      "Batch 635/937, Loss: 0.3609\n",
      "Batch 636/937, Loss: 0.3185\n",
      "Batch 637/937, Loss: 0.1732\n",
      "Batch 638/937, Loss: 0.2575\n",
      "Batch 639/937, Loss: 0.1520\n",
      "Batch 640/937, Loss: 0.1323\n",
      "Batch 641/937, Loss: 0.0731\n",
      "Batch 642/937, Loss: 0.3109\n",
      "Batch 643/937, Loss: 0.1461\n",
      "Batch 644/937, Loss: 0.1854\n",
      "Batch 645/937, Loss: 0.1717\n",
      "Batch 646/937, Loss: 0.1965\n",
      "Batch 647/937, Loss: 0.1544\n",
      "Batch 648/937, Loss: 0.1610\n",
      "Batch 649/937, Loss: 0.1981\n",
      "Batch 650/937, Loss: 0.2176\n",
      "Batch 651/937, Loss: 0.2400\n",
      "Batch 652/937, Loss: 0.3631\n",
      "Batch 653/937, Loss: 0.1372\n",
      "Batch 654/937, Loss: 0.2979\n",
      "Batch 655/937, Loss: 0.1121\n",
      "Batch 656/937, Loss: 0.1306\n",
      "Batch 657/937, Loss: 0.4143\n",
      "Batch 658/937, Loss: 0.1473\n",
      "Batch 659/937, Loss: 0.0894\n",
      "Batch 660/937, Loss: 0.1490\n",
      "Batch 661/937, Loss: 0.1030\n",
      "Batch 662/937, Loss: 0.1679\n",
      "Batch 663/937, Loss: 0.1337\n",
      "Batch 664/937, Loss: 0.1710\n",
      "Batch 665/937, Loss: 0.2697\n",
      "Batch 666/937, Loss: 0.1907\n",
      "Batch 667/937, Loss: 0.1387\n",
      "Batch 668/937, Loss: 0.1827\n",
      "Batch 669/937, Loss: 0.0679\n",
      "Batch 670/937, Loss: 0.1597\n",
      "Batch 671/937, Loss: 0.3536\n",
      "Batch 672/937, Loss: 0.3179\n",
      "Batch 673/937, Loss: 0.1699\n",
      "Batch 674/937, Loss: 0.1431\n",
      "Batch 675/937, Loss: 0.2481\n",
      "Batch 676/937, Loss: 0.2682\n",
      "Batch 677/937, Loss: 0.1575\n",
      "Batch 678/937, Loss: 0.1768\n",
      "Batch 679/937, Loss: 0.1161\n",
      "Batch 680/937, Loss: 0.1392\n",
      "Batch 681/937, Loss: 0.1521\n",
      "Batch 682/937, Loss: 0.1394\n",
      "Batch 683/937, Loss: 0.2565\n",
      "Batch 684/937, Loss: 0.1592\n",
      "Batch 685/937, Loss: 0.2858\n",
      "Batch 686/937, Loss: 0.1784\n",
      "Batch 687/937, Loss: 0.1845\n",
      "Batch 688/937, Loss: 0.2336\n",
      "Batch 689/937, Loss: 0.3518\n",
      "Batch 690/937, Loss: 0.4082\n",
      "Batch 691/937, Loss: 0.2535\n",
      "Batch 692/937, Loss: 0.1159\n",
      "Batch 693/937, Loss: 0.1096\n",
      "Batch 694/937, Loss: 0.1590\n",
      "Batch 695/937, Loss: 0.1981\n",
      "Batch 696/937, Loss: 0.1623\n",
      "Batch 697/937, Loss: 0.2005\n",
      "Batch 698/937, Loss: 0.1906\n",
      "Batch 699/937, Loss: 0.1317\n",
      "Batch 700/937, Loss: 0.2311\n",
      "Batch 701/937, Loss: 0.1468\n",
      "Batch 702/937, Loss: 0.3360\n",
      "Batch 703/937, Loss: 0.2604\n",
      "Batch 704/937, Loss: 0.0979\n",
      "Batch 705/937, Loss: 0.2694\n",
      "Batch 706/937, Loss: 0.2377\n",
      "Batch 707/937, Loss: 0.1747\n",
      "Batch 708/937, Loss: 0.3113\n",
      "Batch 709/937, Loss: 0.0954\n",
      "Batch 710/937, Loss: 0.1385\n",
      "Batch 711/937, Loss: 0.1078\n",
      "Batch 712/937, Loss: 0.3185\n",
      "Batch 713/937, Loss: 0.2476\n",
      "Batch 714/937, Loss: 0.2618\n",
      "Batch 715/937, Loss: 0.1798\n",
      "Batch 716/937, Loss: 0.1571\n",
      "Batch 717/937, Loss: 0.3726\n",
      "Batch 718/937, Loss: 0.1691\n",
      "Batch 719/937, Loss: 0.0812\n",
      "Batch 720/937, Loss: 0.2285\n",
      "Batch 721/937, Loss: 0.1416\n",
      "Batch 722/937, Loss: 0.1462\n",
      "Batch 723/937, Loss: 0.1188\n",
      "Batch 724/937, Loss: 0.1390\n",
      "Batch 725/937, Loss: 0.1963\n",
      "Batch 726/937, Loss: 0.0855\n",
      "Batch 727/937, Loss: 0.1596\n",
      "Batch 728/937, Loss: 0.1901\n",
      "Batch 729/937, Loss: 0.1522\n",
      "Batch 730/937, Loss: 0.2096\n",
      "Batch 731/937, Loss: 0.1796\n",
      "Batch 732/937, Loss: 0.2322\n",
      "Batch 733/937, Loss: 0.1574\n",
      "Batch 734/937, Loss: 0.1738\n",
      "Batch 735/937, Loss: 0.2643\n",
      "Batch 736/937, Loss: 0.2234\n",
      "Batch 737/937, Loss: 0.1750\n",
      "Batch 738/937, Loss: 0.1458\n",
      "Batch 739/937, Loss: 0.2974\n",
      "Batch 740/937, Loss: 0.2802\n",
      "Batch 741/937, Loss: 0.2275\n",
      "Batch 742/937, Loss: 0.1664\n",
      "Batch 743/937, Loss: 0.2156\n",
      "Batch 744/937, Loss: 0.1575\n",
      "Batch 745/937, Loss: 0.3244\n",
      "Batch 746/937, Loss: 0.2869\n",
      "Batch 747/937, Loss: 0.1351\n",
      "Batch 748/937, Loss: 0.0446\n",
      "Batch 749/937, Loss: 0.1611\n",
      "Batch 750/937, Loss: 0.1597\n",
      "Batch 751/937, Loss: 0.2220\n",
      "Batch 752/937, Loss: 0.0761\n",
      "Batch 753/937, Loss: 0.2264\n",
      "Batch 754/937, Loss: 0.1852\n",
      "Batch 755/937, Loss: 0.1741\n",
      "Batch 756/937, Loss: 0.2420\n",
      "Batch 757/937, Loss: 0.2469\n",
      "Batch 758/937, Loss: 0.2288\n",
      "Batch 759/937, Loss: 0.3268\n",
      "Batch 760/937, Loss: 0.1287\n",
      "Batch 761/937, Loss: 0.1873\n",
      "Batch 762/937, Loss: 0.0674\n",
      "Batch 763/937, Loss: 0.3558\n",
      "Batch 764/937, Loss: 0.0703\n",
      "Batch 765/937, Loss: 0.1504\n",
      "Batch 766/937, Loss: 0.1499\n",
      "Batch 767/937, Loss: 0.2181\n",
      "Batch 768/937, Loss: 0.1678\n",
      "Batch 769/937, Loss: 0.0532\n",
      "Batch 770/937, Loss: 0.1273\n",
      "Batch 771/937, Loss: 0.2722\n",
      "Batch 772/937, Loss: 0.2105\n",
      "Batch 773/937, Loss: 0.3403\n",
      "Batch 774/937, Loss: 0.3103\n",
      "Batch 775/937, Loss: 0.1811\n",
      "Batch 776/937, Loss: 0.1060\n",
      "Batch 777/937, Loss: 0.1145\n",
      "Batch 778/937, Loss: 0.1813\n",
      "Batch 779/937, Loss: 0.0922\n",
      "Batch 780/937, Loss: 0.1557\n",
      "Batch 781/937, Loss: 0.0907\n",
      "Batch 782/937, Loss: 0.2156\n",
      "Batch 783/937, Loss: 0.2629\n",
      "Batch 784/937, Loss: 0.1852\n",
      "Batch 785/937, Loss: 0.1544\n",
      "Batch 786/937, Loss: 0.1362\n",
      "Batch 787/937, Loss: 0.2107\n",
      "Batch 788/937, Loss: 0.1242\n",
      "Batch 789/937, Loss: 0.1236\n",
      "Batch 790/937, Loss: 0.1117\n",
      "Batch 791/937, Loss: 0.2340\n",
      "Batch 792/937, Loss: 0.2904\n",
      "Batch 793/937, Loss: 0.1163\n",
      "Batch 794/937, Loss: 0.0938\n",
      "Batch 795/937, Loss: 0.0501\n",
      "Batch 796/937, Loss: 0.1561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 1/20 [00:12<03:59, 12.60s/it, loss=0.435, accuracy=85.38%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 797/937, Loss: 0.1265\n",
      "Batch 798/937, Loss: 0.1909\n",
      "Batch 799/937, Loss: 0.0595\n",
      "Batch 800/937, Loss: 0.3965\n",
      "Batch 801/937, Loss: 0.2824\n",
      "Batch 802/937, Loss: 0.0986\n",
      "Batch 803/937, Loss: 0.0757\n",
      "Batch 804/937, Loss: 0.1242\n",
      "Batch 805/937, Loss: 0.2410\n",
      "Batch 806/937, Loss: 0.1760\n",
      "Batch 807/937, Loss: 0.2600\n",
      "Batch 808/937, Loss: 0.0786\n",
      "Batch 809/937, Loss: 0.1607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pbar:\n\u001b[32m      5\u001b[39m     data, one_hot_labels = shuffle(data, one_hot_labels)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[43mnet\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_hot_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlossfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcross_entropy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     y_hat = net.predict(data)\n\u001b[32m      9\u001b[39m     loss = cross_entropy_loss(one_hot_labels, y_hat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/PJ1/lib/Net.py:100\u001b[39m, in \u001b[36mNet.train\u001b[39m\u001b[34m(self, X, Y, batch_size, lr, lossfunc)\u001b[39m\n\u001b[32m     98\u001b[39m \u001b[38;5;66;03m# 反向传播\u001b[39;00m\n\u001b[32m     99\u001b[39m dL = \u001b[38;5;28mself\u001b[39m.loss_derivative(Y_batch, y_hat)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBatch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39m\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X)\u001b[38;5;250m \u001b[39m//\u001b[38;5;250m \u001b[39mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.loss(Y_batch,\u001b[38;5;250m \u001b[39my_hat)\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/PJ1/lib/Net.py:74\u001b[39m, in \u001b[36mNet.backward\u001b[39m\u001b[34m(self, outputs, dL, lr)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, outputs, dL, lr):\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.net) - \u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         dL = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/AI/PJ1/lib/Net.py:166\u001b[39m, in \u001b[36mMlp.backward\u001b[39m\u001b[34m(self, X, dL, lr)\u001b[39m\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m X.shape == (batch_size, \u001b[38;5;28mself\u001b[39m.input_dim)\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m dL.shape == (batch_size, \u001b[38;5;28mself\u001b[39m.output_dim)\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m Z = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mW\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.b\n\u001b[32m    167\u001b[39m dZ = \u001b[38;5;28mself\u001b[39m.derivative(Z, dL)\n\u001b[32m    168\u001b[39m dW = np.dot(dZ.T, X) / batch_size\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "pbar =tqdm(range(epochs))\n",
    "\n",
    "for i in pbar:\n",
    "    data, one_hot_labels = shuffle(data, one_hot_labels)\n",
    "    net.train(data, one_hot_labels, batch_size=64, lr=0.1, lossfunc=\"cross_entropy\")\n",
    "\n",
    "    y_hat = net.predict(data)\n",
    "    loss = cross_entropy_loss(one_hot_labels, y_hat)\n",
    "    y_hat = np.argmax(y_hat, axis=1)    # (60000, 10) -> (60000,)\n",
    "    accuracy = np.mean(y_hat == one_hot_labels.argmax(axis=1))\n",
    "    pbar.set_postfix({\"loss\": loss, \"accuracy\": f\"{accuracy*100:.2f}%\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951d10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to ../model/task1/MNIST.json\n"
     ]
    }
   ],
   "source": [
    "#net.save_params(modelpath_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ac8f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters loaded from ../model/task1/MNIST.json\n"
     ]
    }
   ],
   "source": [
    "net.load_params(modelpath_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be3202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datapath = \"../test/MNIST/t10k-images.idx3-ubyte\"\n",
    "test_labelpath = \"../test/MNIST/t10k-labels.idx1-ubyte\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be393dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.92%\n"
     ]
    }
   ],
   "source": [
    "test_data = idx2numpy.convert_from_file(test_datapath)    # (60000, 28, 28)\n",
    "test_data = np.expand_dims(test_data, axis=1)             # 添加通道维度 -> (60000, 1, 28, 28)\n",
    "\n",
    "test_label = idx2numpy.convert_from_file(test_labelpath)\n",
    "\n",
    "y_hat = net.predict(test_data)\n",
    "\n",
    "accuracy = np.mean(np.argmax(y_hat, axis=1) == test_label)\n",
    "print(f\"Test accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
